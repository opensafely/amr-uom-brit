---
title: "lrti_appro_model_2019"
author: "Billy"
date: "18/05/2022"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
knitr::opts_knit$set(root.dir = '/workspace')
```


```{r message=FALSE, warning=FALSE, include=FALSE}
library("dplyr")
library("tidyverse")
library("lubridate")
library("foreign")
library("nnet")
library("ggplot2")
library("VGAM")
library("bayesm")
library("finalfit")
library("here")

```

```{r include=FALSE}
DF <- read_csv(here::here("output","lrti_outcome_2019.csv"))
DF <- DF %>% filter (age>3)
DF <- DF %>% mutate(age_group = case_when(age>3 & age<=15 ~ "<16",
                                              age>=16 & age<=44 ~ "16-44",
                                              age>=45 & age<=64 ~ "45-64",
                                              age>=65 ~ "65+"))
DF$outcome <- as.factor(DF$outcome)
DF$outcome <- as.factor(DF$outcome)
DF$ethnicity_6 <- as.factor(DF$ethnicity_6)
DF$imd <- as.factor(DF$imd)
DF$region <- as.factor(DF$region)
DF$charlsonGrp <- as.factor(DF$charlsonGrp)
DF$age_group <- as.factor(DF$age_group)
DF$age_group <- relevel(DF$age_group, ref = "16-44")
DF$outcome <- relevel(DF$outcome, ref = "1")
DF$ethnicity_6 <- relevel(DF$ethnicity_6, ref = "White")
DF$imd <- relevel(DF$imd, ref = "1")
DF$region <- relevel(DF$region, ref = "East")
DF$charlsonGrp <- relevel(DF$charlsonGrp, ref = "zero")
DF <- DF %>% dplyr::select(outcome,age_group,sex,ethnicity_6,region,charlsonGrp,imd)
DF <- DF %>% filter (DF$sex=="M"|DF$sex=="F")
DF <- DF %>% filter (!is.na(outcome))
```

```{r include=FALSE}

# Data Partition 
set.seed(777)
ind <- sample(2,nrow(DF),
              replace = TRUE,
              prob = c(0.75,0.25))

training <- DF[ind==1,]
testing <- DF[ind==2,]

### use training dataset to develop the model
m0 <- multinom(outcome ~ age_group + sex ,data = training)
m1 <- multinom(outcome ~.,data = training)
fit.multinomial <- vgam(outcome ~., family = multinomial(ref = "1"), data = training)
```

```{r echo=TRUE}
summary(m1)
```

```{r echo=TRUE}
### 2-tailed Z-test
z <- summary(m1)$coefficients/summary(m1)$standard.errors
p <- (1 - pnorm(abs(z),0,1)) * 2
p
```


```{r echo=TRUE}
###relative risk ratio ###
exp(coef(m1))
```


```{r echo=TRUE}
### Confusion Matrix & Misclassification Error - Training Data
p <- predict(m1,training)
tab <- table(p, training$outcome)
tab
```

```{r echo=TRUE}
sum(diag(tab))/sum(tab)
```

```{r echo=TRUE}
1-sum(diag(tab))/sum(tab)
```

```{r echo=TRUE}
### Confusion Matrix & Misclassification Error - Testing data
p1 <- predict(m1,testing)
tab1 <- table(p1, testing$outcome)
tab1
```

```{r echo=TRUE}
1-sum(diag(tab1))/sum(tab1)
```


```{r echo=TRUE}
### Table 1. Description and descriptive statistics for the case studies for each outcome category separately.
# columns for  table
colsfortab <- colnames(training)
training %>% summary_factorlist(explanatory = colsfortab) -> t1
t1
```

```{r echo=TRUE}
testing %>% summary_factorlist(explanatory = colsfortab) -> t2
t2
```

```{r echo=TRUE}
### Table 2. Assessment of calibration-in-the-large in the validation data.
n <- table(testing$outcome)
n/sum(n)
```

```{r echo=TRUE}
tab1/colSums(tab1)
```


### Parametric nominal calibration plot for the validation data of the ovarian tumor case study for each outcome category separately ((a)â€“(c)) and overall (d).

```{r echo=TRUE}
outcome=testing$outcome
k=3
p <- predict(fit.multinomial , newdata = testing,type="response")
LP <- predict(fit.multinomial, newdata = testing)
r=1
estimates=FALSE
dfr=2
plotoverall=TRUE
datapoints=TRUE
smoothing=TRUE
smoothpar=1
intercept=FALSE
slope=FALSE
test=FALSE
  # probabilities
  probs <- split(p,col(p))    
  
  # linear predictors necessary for non-parametric calibration plot - give a name to each linear predictor 
  # seperately
  lps <- split(LP,col(LP))
  for(i in 1:(k-1)){assign(paste("lp", i, sep = ""),unlist(lps[[i]]))}
head(LP)

```
