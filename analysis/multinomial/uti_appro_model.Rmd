---
title: "uti_appro_model"
author: "Billy"
date: "30/05/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/workspace')
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library("dplyr")
library("tidyverse")
library("lubridate")
library("foreign")
library("nnet")
library("ggplot2")
library("VGAM")
library("bayesm")
library("finalfit")
library("here")
library("rms")
library("pROC")

```

```{r echo=FALSE}
DF <- read_csv(here::here("output","uti_outcome.csv"))
DF <- DF %>% filter (age>3)
DF$outcome <- as.factor(DF$outcome)
DF$ethnicity_6 <- as.factor(DF$ethnicity_6)
DF$imd <- as.factor(DF$imd)
DF$region <- as.factor(DF$region)
DF$charlsonGrp <- as.factor(DF$charlsonGrp)
DF$ab12b4 <- as.factor(DF$ab12b4)                                            
DF$outcome <- relevel(DF$outcome, ref = "1")
DF$ethnicity_6 <- relevel(DF$ethnicity_6, ref = "White")
DF$imd <- relevel(DF$imd, ref = "1")
DF$region <- relevel(DF$region, ref = "East")
DF$charlsonGrp <- relevel(DF$charlsonGrp, ref = "zero")
DF$ab12b4 <- relevel(DF$ab12b4, ref = "0")
DF <- DF %>% dplyr::select(outcome,age,sex,ethnicity_6,region,charlsonGrp,imd,ab12b4)
DF <- DF %>% filter (DF$sex=="M"|DF$sex=="F")
DF <- DF %>% filter (!is.na(outcome))
DF <- DF %>% filter (!is.na(ethnicity_6))
DF <- DF %>% filter (!is.na(imd))
DF <- DF %>% filter (!is.na(region))
DF <- DF %>% filter (!is.na(charlsonGrp))
DF <- DF %>% filter (!is.na(age))
DF <- DF %>% filter (!is.na(sex))
DF <- DF %>% filter (!is.na(ab12b4))
```

## model summary
```{r echo=FALSE}

# Data Partition 
set.seed(777)
ind <- sample(2,nrow(DF),
              replace = TRUE,
              prob = c(0.75,0.25))

training <- DF[ind==1,]
testing <- DF[ind==2,]

### use training dataset to develop the model
Knots.manual <- rcspline.eval(training$age, nk = 5, knots.only = TRUE)
m1 <- vgam(outcome ~ rcs(age, Knots.manual) + sex + ethnicity_6 + region + charlsonGrp + imd + ab12b4,  family = multinomial(parallel = FALSE, refLevel = 1), data =training)
summaryvglm(m1)
```
## Age cut-off value
```{r echo=FALSE}
attributes(rcs(training$age, Knots.manual))$parms
```
## coefficients 95% CI 
```{r echo=FALSE}
### coefficients 95% CI ###
confintvglm(m1,matrix=TRUE)
```
##relative risk ratio 
```{r echo=FALSE}
###relative risk ratio ###
exp(coefficients(m1,matrix=TRUE))
```

##relative risk ratio 95% CI 
```{r echo=FALSE}
###relative risk ratio 95% CI ###
exp(confintvglm(m1,matrix=TRUE))
```

## Training dataset summary
```{r echo=FALSE}
### Table 1. Description and descriptive statistics for the case studies for each outcome category separately.
# columns for  table
colsfortab <- colnames(training)
training %>% summary_factorlist(explanatory = colsfortab) -> t1
t1
```
## Testing dataset summary
```{r echo=FALSE}
testing %>% summary_factorlist(explanatory = colsfortab) -> t2
t2
```


### Parametric nominal calibration plot for the validation data of the ovarian tumor case study for each outcome category separately ((a)â€“(c)) and overall (d).

```{r echo=FALSE}
outcome=testing$outcome
k=3
p <- predict(m1 , newdata = testing,type="response")
LP <- predict(m1, newdata = testing)
r=1
estimates=TRUE
dfr=2
plotoverall=TRUE
datapoints=TRUE
smoothing=TRUE
smoothpar=1
intercept=TRUE
slope=TRUE
test=TRUE
  # probabilities
  probs <- split(p,col(p))    
  
  # linear predictors necessary for non-parametric calibration plot - give a name to each linear predictor 
  # seperately
  lps <- split(LP,col(LP))
  for(i in 1:(k-1)){assign(paste("lp", i, sep = ""),unlist(lps[[i]]))}
aaa <- length(LP[,1])
bbb <- length(outcome)
cbind(aaa,bbb)
```


```{r echo=FALSE}
  ###############################################
  # parametric logistic recalibration framework 
  # cf. section 2.2.1.                          
  ###############################################
  
  # reference category r
  # LP = matrix with linear predictors


  fitp<-vglm(outcome~LP,family=multinomial(refLevel=r))
  if(isTRUE(estimates)){est<-coefficients(fitp)
  names(est) <- paste('EST',names(est),sep='.')}
  
```





```{r echo=FALSE}
  
  fitnp<-vgam(outcome~s(lp1,df=dfr)+s(lp2,df=dfr),family=multinomial(refLevel=r))
  
  
  ###############################################                  
  # Separate (non-)parametric calibration plots
  ###############################################
  
  
  par(mfrow=c(ceiling(k/2),2))
  for(i in 1:k){p <- unlist(probs[[i]])
  if(isTRUE(smoothing)){color<-'grey'}else{color<-1+i}
 
  matplot(p,fitted(fitp)[,i],type="p",pch=i,col=color,lwd=1,ylab="",xlab="",xlim=0:1,ylim=0:1)
  par(new=T)
  ref <- rbind(c(0,0),c(1,1))
  matplot(ref,ref,type="l",col=1,lwd=2,ylab="Observed proportions",xlab="Predicted probabilities",xlim=0:1,ylim=0:1)
  # smoother for calibration plots 
  ##################################
  # a = smoothing parameter
  if(isTRUE(smoothing)){
    a = smoothpar
    points(smooth.spline(p, fitted(fitp)[,i],spar=a), type="l", col=(1+i), lwd = 4)}
  # legend
  legende <- c(paste( i, sep = ""))
  legend(x=0.6, y=(0.2),col=(1+i),lty =1,legend=legende)
  title(main = "Parametric calibration plot")
  par(new=F)} 
```


```{r echo=FALSE}
  
  # non-parametric calibration plot 
  # cf. section 2.2.2.              
  ###################################
  
  par(mfrow=c(ceiling(k/2),2))
  for(i in 1:k){p <- unlist(probs[[i]])
  if(isTRUE(smoothing)){color<-'grey'}else{color<-1+i}
  plot2 <- matplot(p,fitted(fitnp)[,i],type="p",pch=i,col=color,lwd=1,ylab="",xlab="",xlim=0:1,ylim=0:1)
  par(new=T)
  ref <- rbind(c(0,0),c(1,1))
  matplot(ref,ref,type="l",col=1,lwd=2,ylab="Observed proportions",xlab="Predicted probabilities",xlim=0:1,ylim=0:1)
  # smoother for calibration plots 
  ##################################
  # a = smoothing parameter
  if(isTRUE(smoothing)){
    a = smoothpar
    points(smooth.spline(p, fitted(fitnp)[,i],spar=a), type="l", col=(1+i), lwd = 4)}
  # legend
  legende <- c(paste(i, sep = ""))
  legend(x=0.6, y=(0.2),col=(1+i),lty =1,legend=legende)
  title(main = "Non-parametric calibration plot")
  par(new=F)}
  
```



```{r echo=FALSE}
  if(isTRUE(plotoverall)){
    
    
    # parametric calibration plot 
    # cf. section 2.2.2.          
    ###############################
    
    if(isTRUE(datapoints)){for(i in 1:k){p <- unlist(probs[[i]])
    plot3 <- matplot(p,fitted(fitp)[,i],type="p",pch=i,col=(1+i),lwd=1,ylab="",xlab="",xlim=0:1,ylim=0:1)
    par(new=T)}}
    ref <- rbind(c(0,0),c(1,1))
    matplot(ref,ref,type="l",col=1,lwd=2,ylab="Observed proportions",xlab="Predicted probabilities",xlim=0:1,ylim=0:1)
    # smoother for calibration plots 
    ##################################
    # a = smoothing parameter
    if(isTRUE(smoothing)){
      a = smoothpar
      for(i in 1:k){p <- unlist(probs[[i]])
      points(smooth.spline(p, fitted(fitp)[,i],spar=a), type="l", col=(1+i), lwd = 4)}}
    # legend
    for(i in 1:k){if(i <= 2){legende <- c("1","2")}
      if(i > 2){legende <- c(legende,paste(i, sep = ""))}}
    legend(x=0.7, y=(0.20+(k-3)*0.05),col=2:(k+1),lty =1,legend=legende)
    title(main = "Parametric calibration plot")
    par(new=F)
    
    # non-parametric calibration plot 
    # cf. section 2.2.2.              
    ###################################
    
    
    if(isTRUE(datapoints)){for(i in 1:k){p <- unlist(probs[[i]])
    plot4 <- matplot(p,fitted(fitnp)[,i],type="p",pch=i,col=(1+i),lwd=1,ylab="",xlab="",xlim=0:1,ylim=0:1)
    par(new=T)}}
    ref <- rbind(c(0,0),c(1,1))
    matplot(ref,ref,type="l",col=1,lwd=2,ylab="Observed proportions",xlab="Predicted  probabilities",xlim=0:1,ylim=0:1)
    # smoother for calibration plots 
    ##################################
    # a = smoothing parameter
    if(isTRUE(smoothing)){a = smoothpar
    for(i in 1:k){p <- unlist(probs[[i]])
    points(smooth.spline(p, fitted(fitnp)[,i],spar=a), type="l", col=(1+i), lwd = 4)}}
    # legend
    for(i in 1:k){if(i <= 2){legende <- c("1","2")}
      if(i > 2){legende <- c(legende,paste( i, sep = ""))}}
    legend(x=0.7, y=(0.20+(k-3)*0.05),col=2:(k+1),lty =1,legend=legende)
    title(main = "Non-parametric calibration plot")
    par(new=F)}
```

```{r echo=FALSE}
  ########################################
  # estimation of calibration intercepts 
  # cf. section 2.2.3. and 2.2.4.        
  ########################################
  
  if(isTRUE(intercept)){int<-vgam(outcome~1,offset=LP,family=multinomial(refLevel=r))
  coeffint<-coefficients(int)
  se<-sqrt(diag(vcov(int)))
  ci1i <- cbind(LL1 = coeffint[1] - qnorm(0.975) * se[1], UL1 = coeffint[1] + qnorm(0.975) * se[1])
  ci2i <- cbind(LL2 = coeffint[2] - qnorm(0.975) * se[2], UL2 = coeffint[2] + qnorm(0.975) * se[2])
  estint <- c(coeffint[1],ci1i,coeffint[2],ci2i)
  names(estint) <- paste('CALINT',c('int1','LLint1','ULint1','int2','LLint2','ULint2'),sep='.')}
  
  
  ####################################
  # estimation of calibration slopes 
  # cf. section 2.2.3. and 2.2.4.    
  ####################################
  
  # we used constraints to fix some coefficients to zero as appropriate
  # for k outcome categories this code should be changed to:
  # i <- diag(k-1)
  # i2 <- cbind(c(1,rep(0,k-2)))
  # i3 <- cbind(c(0,1,rep(0,k-1)))
  # i4 <- cbind(c(0,0,1,rep(0,k-2)))
  # ... (ij <- cbind(c(rep(0,j-2),1,rep(0,k-j)))
  # ik <- cbind(c(rep(0,k-2),1))
  # clist<-list("(Intercept)"=i,"lp1"=i2,"lp2"=i3,...,"lpk-1"=ik)
  # slopes<-vgam(outcome~lp1+lp2+...+lpk-1,family=multinomial(refLevel=r),constraints=clist)
  
  if(isTRUE(slope)){i<-diag(k-1)
  i2<-rbind(1,0)
  i3<-rbind(0,1)
  clist<-list("(Intercept)"=i,"lp1"=i2,"lp2"=i3)
  slopes<-vgam(outcome~lp1+lp2,family=multinomial(refLevel=r),constraints=clist)
  coeffslopes<-coefficients(slopes)[k:length(coefficients(slopes))]
  se<-sqrt(diag(vcov(slopes)))
  ci1s <- cbind(LL1 = coeffslopes[1] - qnorm(0.975) * se[3], UL1 = coeffslopes[1] + qnorm(0.975) * se[3])
  ci2s <- cbind(LL2 = coeffslopes[2] - qnorm(0.975) * se[4], UL2 = coeffslopes[2] + qnorm(0.975) * se[4])
  estslopes <- c(coeffslopes[1],ci1s,coeffslopes[2],ci2s)
  names(estslopes) <- paste('CALSLOPES',c('lp1','LLlp1','ULlp1','lp2','LLlp2','ULlp2'),sep='.')}
  
  
  #################################
  # calibration testing          
  # cf. section 2.2.3. and 2.2.4. 
  #################################
  
  # this code requires the bayesm library developed by Peter Rossi
  
  if(isTRUE(test)){
    
    # -2 log-likelihood of model without adaptations
    # for k outcome categories this code should be changed to:
    # alphas <- rep(0,k-1) #(i.e. all intercepts zero)
    # beta1 <- c(1,rep(0,k-2)) #(i.e. first linear predictor for first equation)
    # beta2 <- c(0,1,rep(0,k-3)) #(i.e. second linear predictor for second equation)      
    # betaj <- c(rep(0,j-1),1,rep(0,k-1-j)) #(i.e. jth linear predictor for jth equation)
    # betak <- c(rep(0,k-2),1) #(i.e. kth linear predictor for kth equation)
    # parametersk <- c(alphas, beta1, beta2, ..., betak)
    
    parametersk <- c(0,0,1,0,0,1) #c(alpha1,alpha2,b22,b23,b32,b33)
    Xdk=LP
    x <- createX(p=k,na=0,nd=k-1,Xa=NULL,Xd=Xdk,INT=TRUE,DIFF=FALSE,base=1)
    deviancewithout <- -2*llmnl(parametersk,outcome,x)
    names(deviancewithout)<-c('original deviance')
    
    devint <- deviance(int)
    names(devint)<-c('intercept deviance')
    devslopes <- deviance(slopes)
    names(devslopes)<-c('slopes deviance')
    
    # overall calibration (i.e. calibration intercepts and slopes) 
    ################################################################
    
    poverall<- pchisq(deviancewithout - devslopes, df = 2*(k-1), lower.tail = FALSE)
    
    # calibration intercepts 
    ##########################
    
    pint<- pchisq(deviancewithout - devint, df = k-1, lower.tail = FALSE)
    
    # calibration slopes 
    ######################
    
    pslopes<- pchisq(devint - devslopes, df = k-1, lower.tail = FALSE)
    names(poverall)<-c('p overall')
    names(pint)<-c('p int')
    names(pslopes)<-c('p slopes')}
  
  # Printing of results
  # The probabilities of calibration intercepts and slopes are only shown when the hypothesis of perfect 
  # calibration is rejected.
  
  results<-list(if(isTRUE(estimates)){est}else{'Not requested'},if(isTRUE(intercept)){estint}else{'Not requested'},if(isTRUE(slope)){estslopes}else{'Not requested'},if(isTRUE(test)){c(deviancewithout,devint,devslopes)}else{'Not requested'},if(isTRUE(test)){c(poverall,if(poverall<0.05){c(pint,pslopes)})}else{'Not requested'})
  names(results)<-c("Coefficients of parametric recalibration framework","Calibration Intercepts with 95% CI","Calibration Slopes with 95% CI","Deviances","P-values")
  n <- 1:5
  selection <- c(isTRUE(estimates),isTRUE(intercept),isTRUE(slope),isTRUE(test),isTRUE(test))
  results[n[selection]]
```



### Discrimination
### polytomous discrimination index  
```{r echo=FALSE}
#Estimates of PDI and its components
testing$outcome <- as.numeric(testing$outcome)
p <- predict(m1 , newdata = testing,type="response")
df.p <- as.data.frame(p)
head(df.p)
data <- (cbind(testing$outcome,df.p))
```


```{r echo=FALSE}
names(data) <- c("outcome","p1","p2","p3")
pdiest<-function(data){
  
  y<-data$outcome
  ymin<-min(y)
  ymax<-max(y)
  noutcome<-ymax-ymin
  p<-prod(table(y))
  pdi<-c()
  
  for (i in 1:(noutcome+1)){
    
    predprob<-data[,(i+1)]  #READ predicted probabilities for level i
    t0<-table(predprob,y)   #CALCULATE frequencies of predicted probabilities for level i by outcome
    
    dim1<-dim(t0)[1]
    dim2<-dim(t0)[2]
    t<-cbind(t0[,i],t0[,-i]) #REORDER columns
    restrictt<- if (noutcome == 1){matrix(t[,2:(noutcome+1)],ncol=1)} else {t[,2:(noutcome+1)] } #REMOVE first column of t
    
    c<-apply(restrictt,2,cumsum) #CALCULATE cumulative frequencies of predicted probabilities for level i by outcome
    cnew<- if (noutcome == 1) {rbind(rep(0,noutcome),matrix(c[1:(dim(c)[1]-1),],ncol=))} else {rbind(rep(0,noutcome),c[1:(dim(c)[1]-1),])} #INTRODUCE a row of zeros at the begining of c
    
    mat<-c()                     #MATRIX of 0s and 1s of dimension 2^(noutcome) x noutcome
    for (j in 1:noutcome){
      mat0<-cbind(mat,0)
      mat1<-cbind(mat,1)
      mat<-rbind(mat0,mat1)}
    
    r<-0
    for (k in 1:dim(mat)[1]){
      dt<-t(apply(restrictt, 1, function(x) mat[k,]*x))
      dcnew<-t(apply(cnew, 1, function(x) (1-mat[k,])*x))
      dfinal<-if (noutcome == 1) {cbind(t[,1],t(dt+dcnew))} else {cbind(t[,1],dt+dcnew)} #TAKE all combinations of frequencies and cumulative frequencies
      r<-r+sum(apply(dfinal,1,prod))/(1+sum(mat[k,]))}                                   #MULTIPLYIES across rows
    
    r<-r/p     #PDI component for outcome i
    pdi<-rbind(pdi,r)
  }
  pdi<-rbind(mean(pdi),pdi)
  pdi}

#Estimates and bootstrap 95% confidence intervals for PDI and its components
pdifunction<-function(data,nbs){
  #PDI estimate
  estimate<-pdiest(data)
  #BOOTSTRAP
  samplesize<-dim(data)[1]
  for (i in 1:nbs)
  {vec<-sample.int(samplesize,size=samplesize, replace=TRUE)
  mydatabs<-data[vec,]
  if (i<2) {pdibs<-pdiest(mydatabs)
  } else {
    pdibs<-cbind(pdibs,pdiest(mydatabs))
  }
  }
  
  stderr <- sqrt(apply(pdibs, 1, var))
  lowerci<- pmax(0, estimate - 1.96*stderr)
  upperci<- pmin(1, estimate + 1.96*stderr)
  
  estci<-cbind(estimate, lowerci, upperci)
  estci
}
```

```{r echo=FALSE}
pdiest(data)
```
#Estimates and bootstrap 95% confidence intervals for PDI and its components
```{r echo=FALSE}
pdifunction(data,5)
```




###"In one study's opinion, the pairwise approach is superior to the 1-versus-rest approach"
###"1-versus-rest approach"
###"1 vs rest"
```{r echo=FALSE}
testing <- testing %>% 
  mutate(reoutcome1 = ifelse(outcome == 1 , 1, 0))
# Obtain the c statistic / AUC
c1 <- roc(testing$reoutcome1~df.p$`1`,ci=TRUE)
c1
```
# Plot the ROC curve

```{r echo=FALSE}
plot(roc(testing$reoutcome1,df.p$`1`))
```

# "2 vs rest"
```{r echo=FALSE}
testing <- testing %>% 
  mutate(reoutcome2 = ifelse(outcome == 2 , 1, 0))
# Obtain the c statistic / AUC
c1 <- roc(testing$reoutcome2~df.p$`2`,ci=TRUE)
c1
```

# Plot the ROC curve

```{r echo=FALSE}
plot(roc(testing$reoutcome2,df.p$`2`))
```

# "3 vs rest"

```{r echo=FALSE}
testing <- testing %>% 
  mutate(reoutcome3 = ifelse(outcome == 3 , 1, 0))
# Obtain the c statistic / AUC
c1 <- roc(testing$reoutcome3~df.p$`3`,ci=TRUE)
c1
```

# Plot the ROC curve

```{r echo=FALSE}
plot(roc(testing$reoutcome3,df.p$`3`))
```


### "the pairwise approach "
#"1 vs 2"

```{r echo=FALSE}
testing_1 <- testing %>% 
  filter(outcome ==1|outcome==2) %>% 
  mutate(reoutcome = ifelse(outcome == 1 , 1, 0))

order1 <- testing$outcome ==1|testing$outcome==2
df.p$reoutcome1<- df.p$`1`/(df.p$`1`+df.p$`2`)
df.p1 <- df.p[order1,]
# Obtain the c statistic / AUC
c1 <- roc(testing_1$reoutcome~df.p1$reoutcome1,ci=TRUE)
c1
```

# Plot the ROC curve
```{r echo=FALSE}
plot(roc(testing_1$reoutcome,df.p1$reoutcome1))
```


#"1 vs 3"
```{r echo=FALSE}
testing_2 <- testing %>% 
  filter(outcome ==1|outcome==3) %>% 
  mutate(reoutcome = ifelse(outcome == 1 , 1, 0))
order2 <- testing$outcome ==1|testing$outcome==3
df.p$reoutcome2 <- df.p$`1`/(df.p$`1`+df.p$`3`)
df.p2 <- df.p[order2,]

# Obtain the c statistic / AUC
c1 <- roc(testing_2$reoutcome~df.p2$reoutcome2,ci=TRUE)
c1
```

# Plot the ROC curve
```{r echo=FALSE}
plot(roc(testing_2$reoutcome,df.p2$reoutcome2))
```


#"2 vs 3"
```{r echo=FALSE}
testing_3 <- testing %>% 
  filter(outcome ==2|outcome==3) %>% 
  mutate(reoutcome = ifelse(outcome == 3 , 1, 0))
order3 <- testing$outcome ==2|testing$outcome==3
df.p$reoutcome3 <- df.p$`3`/(df.p$`2`+df.p$`3`)
df.p3 <- df.p[order3,]
# Obtain the c statistic / AUC
c1 <- roc(testing_3$reoutcome~df.p3$reoutcome3,ci=TRUE)
c1
```

# Plot the ROC curve
```{r echo=FALSE}
plot(roc(testing_3$reoutcome,df.p3$reoutcome3))
```

  
  












