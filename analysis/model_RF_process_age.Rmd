---
title: "random sampling by subclass"
---

```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(skimr)
library('tidyverse')

library("ggplot2")

library(caret)
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format="html")
```

https://www.machinelearningplus.com/machine-learning/caret-package/ 

```{r}
#df <- read_rds("/Users/yayang/Documents/GitHub/amr-uom-brit/output/matched_ab.rds")
df <- read_rds(here::here("output","matched_ab.rds"))
count(df)

df=df[!is.na(df$case),]
count(df)
```

sample 1000 patients by subclass
```{r echo=TRUE}
# develop model

set.seed(123)

subclass=levels(df$subclass)
idx=sample(subclass,145)

df=df%>%filter(subclass %in% idx)


table(df$case)

```

add variables
```{r}
#DF <- read_rds("/Users/yayang/Documents/GitHub/amr-uom-brit/output/matched_outcome.rds")
DF<- read_rds(here::here("output","matched_outcome.rds"))
DF=DF%>% select("patient_id","patient_index_date","age")
DF=distinct(DF)

# filter only 1 ID
#df=df %>% distinct(patient_id, .keep_all=T)
data=merge(df,DF,by=c("patient_id","patient_index_date"), all.x = TRUE)

df=data
rm(DF,data)

table(df$case)

```

```{r}
## age grp
df=df%>%mutate(age_group=case_when(case==1 & age<40 ~1,
                                   case==1 & age>=40 & age<60 ~2,
                                   case==1 & age>=60 & age<80 ~3,
                                   case==1 & age>=80 ~4))
df=df%>% group_by(subclass)%>%mutate(age_grp=sum(age_group,na.rm = T))

df=df%>% ungroup(subclass)

```



```{r}
df=df%>% select( "case", "AB_6wk" , "total_ab","ab_types",
              "exposure_period"  ,
               "recent_ab_days",  
              "broad_prop" ,
             "interval_med"  , "interval_CV",
              "length_med" ,  "length_CV" ,
             "prescribe_times","age_grp"
               )
df$exposure_period=-df$exposure_period
df$case=as.factor(df$case)

#
```

handle missing value
replace with 0
```{r}
df[is.na(df)] <- 0
```

indicator for missing value
```{r}
#df$prescribe_time_0=ifelse(is.na(df$prescribe_times),0,1) #1= ab user ,0=non 
#df$prescribe_time_1=ifelse(df$prescribe_times==1,1,0) 
#df$prescribe_time_2=ifelse(df$prescribe_times==2,1,0) 
df$prescribe_time_2=ifelse(df$prescribe_times>=2,1,0) # missing indicator for sd,CV

```




age group1
```{r}
data=df
rm(df)
df=data %>% filter(age_grp==1)

table(df$case)

```

# default
```{r }
x=df[,2:13]
y=df[,1]

control <- trainControl(method='repeatedcv', # repeated cross-validation 
                        number=5,            # 5 folds 
                        repeats=3)           # repeat 3 times

metric <- "Accuracy"  # Metric compare model is Accuracy

set.seed(123)

mtry <- sqrt(ncol(x)) #Randomly Selected Predictors, decorrelated the trees, preventing strong predictors from being selected on the top of every time
tunegrid <- expand.grid(.mtry=mtry)

rf_default <- train(case~., 
                      data=df, 
                      method='rf', 
                      metric='Accuracy', 
                      tuneGrid=tunegrid, 
                      trControl=control)
print(rf_default)

plot(varImp(rf_default,scale = F), main= "Var Imp: RF 5 fold CV")
```

# Random search
```{r eval=FALSE, include=FALSE}
#mtry: Number of random variables collected at each split. In normal equal square number columns.
mtry <- sqrt(ncol(x))

control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3,
                        search = 'random')

#Random generate 15 mtry values with tuneLength = 12
set.seed(1)
rf_random <- train(case ~ .,
                   data = df,
                   method = 'rf',
                   metric = 'Accuracy',
                   tuneLength  = 13, 
                   trControl = control)
print(rf_random)
plot(rf_random)
plot(varImp(rf_random,scale = F), main= "Var Imp: RF 5 fold CV")

```


# Grid search
```{r eval=FALSE, include=FALSE}

#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')
#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = c(1:13) )

rf_gridsearch <- train(case ~ ., 
                       data = df,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid,
                       trControl=control
                  )
print(rf_gridsearch)
plot(rf_gridsearch)
plot(varImp(rf_gridsearch,scale = F), main= "Var Imp: RF 5 fold CV")

```




age group2
```{r}
rm(df)
df=data %>% filter(age_grp==2)

table(df$case)

```

# default
```{r }
x=df[,2:13]
y=df[,1]

control <- trainControl(method='repeatedcv', # repeated cross-validation 
                        number=5,            # 5 folds 
                        repeats=3)           # repeat 3 times

metric <- "Accuracy"  # Metric compare model is Accuracy

set.seed(123)

mtry <- sqrt(ncol(x)) #Randomly Selected Predictors, decorrelated the trees, preventing strong predictors from being selected on the top of every time
tunegrid <- expand.grid(.mtry=mtry)

rf_default <- train(case~., 
                      data=df, 
                      method='rf', 
                      metric='Accuracy', 
                      tuneGrid=tunegrid, 
                      trControl=control)
print(rf_default)

plot(varImp(rf_default,scale = F), main= "Var Imp: RF 5 fold CV")
```

# Random search
```{r eval=FALSE, include=FALSE}
#mtry: Number of random variables collected at each split. In normal equal square number columns.
mtry <- sqrt(ncol(x))

control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3,
                        search = 'random')

#Random generate 15 mtry values with tuneLength = 12
set.seed(1)
rf_random <- train(case ~ .,
                   data = df,
                   method = 'rf',
                   metric = 'Accuracy',
                   tuneLength  = 13, 
                   trControl = control)
print(rf_random)
plot(rf_random)
plot(varImp(rf_random,scale = F), main= "Var Imp: RF 5 fold CV")

```


# Grid search
```{r eval=FALSE, include=FALSE}

#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')
#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = c(1:13) )

rf_gridsearch <- train(case ~ ., 
                       data = df,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid,
                       trControl=control
                  )
print(rf_gridsearch)
plot(rf_gridsearch)
plot(varImp(rf_gridsearch,scale = F), main= "Var Imp: RF 5 fold CV")

```





age group3
```{r}
rm(df)
df=data %>% filter(age_grp==3)
table(df$case)

```

# default
```{r }
x=df[,2:13]
y=df[,1]

control <- trainControl(method='repeatedcv', # repeated cross-validation 
                        number=5,            # 5 folds 
                        repeats=3)           # repeat 3 times

metric <- "Accuracy"  # Metric compare model is Accuracy

set.seed(123)

mtry <- sqrt(ncol(x)) #Randomly Selected Predictors, decorrelated the trees, preventing strong predictors from being selected on the top of every time
tunegrid <- expand.grid(.mtry=mtry)

rf_default <- train(case~., 
                      data=df, 
                      method='rf', 
                      metric='Accuracy', 
                      tuneGrid=tunegrid, 
                      trControl=control)
print(rf_default)

plot(varImp(rf_default,scale = F), main= "Var Imp: RF 5 fold CV")
```

# Random search
```{r eval=FALSE, include=FALSE}
#mtry: Number of random variables collected at each split. In normal equal square number columns.
mtry <- sqrt(ncol(x))

control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3,
                        search = 'random')

#Random generate 15 mtry values with tuneLength = 12
set.seed(1)
rf_random <- train(case ~ .,
                   data = df,
                   method = 'rf',
                   metric = 'Accuracy',
                   tuneLength  = 13, 
                   trControl = control)
print(rf_random)
plot(rf_random)
plot(varImp(rf_random,scale = F), main= "Var Imp: RF 5 fold CV")

```


# Grid search
```{r eval=FALSE, include=FALSE}

#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')
#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = c(1:13) )

rf_gridsearch <- train(case ~ ., 
                       data = df,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid,
                       trControl=control
                  )
print(rf_gridsearch)
plot(rf_gridsearch)
plot(varImp(rf_gridsearch,scale = F), main= "Var Imp: RF 5 fold CV")

```







age group4
```{r}
rm(df)
df=data %>% filter(age_grp==4)
table(df$case)

```

# default
```{r }
x=df[,2:13]
y=df[,1]

control <- trainControl(method='repeatedcv', # repeated cross-validation 
                        number=5,            # 5 folds 
                        repeats=3)           # repeat 3 times

metric <- "Accuracy"  # Metric compare model is Accuracy

set.seed(123)

mtry <- sqrt(ncol(x)) #Randomly Selected Predictors, decorrelated the trees, preventing strong predictors from being selected on the top of every time
tunegrid <- expand.grid(.mtry=mtry)

rf_default <- train(case~., 
                      data=df, 
                      method='rf', 
                      metric='Accuracy', 
                      tuneGrid=tunegrid, 
                      trControl=control)
print(rf_default)

plot(varImp(rf_default,scale = F), main= "Var Imp: RF 5 fold CV")
```

# Random search
```{r eval=FALSE, include=FALSE}
#mtry: Number of random variables collected at each split. In normal equal square number columns.
mtry <- sqrt(ncol(x))

control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3,
                        search = 'random')

#Random generate 15 mtry values with tuneLength = 12
set.seed(1)
rf_random <- train(case ~ .,
                   data = df,
                   method = 'rf',
                   metric = 'Accuracy',
                   tuneLength  = 13, 
                   trControl = control)
print(rf_random)
plot(rf_random)
plot(varImp(rf_random,scale = F), main= "Var Imp: RF 5 fold CV")

```


# Grid search
```{r eval=FALSE, include=FALSE}

#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')
#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = c(1:13) )

rf_gridsearch <- train(case ~ ., 
                       data = df,
                       method = 'rf',
                       metric = 'Accuracy',
                       tuneGrid = tunegrid,
                       trControl=control
                  )
print(rf_gridsearch)
plot(rf_gridsearch)
plot(varImp(rf_gridsearch,scale = F), main= "Var Imp: RF 5 fold CV")

```


