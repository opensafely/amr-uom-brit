{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predcition of Hospital Admission Related to Otitis Externa\n",
    "\n",
    "In this notebook, we develop Cox proportional hazard regression models to predict the risk of hospital admission related to otitis externa. We, then, analyse whether prescribing antibiotics is based on the risk of hospital admission or not by building logistic regression (LR) and random forest (RF) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import logit\n",
    "from datetime import date\n",
    "from operator import attrgetter\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn('DelftStack')\n",
    "warnings.warn('Do not show this message')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0- functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#function to transform cph model summary and save it as html\n",
    "def GetPrintSummary(model):\n",
    "    output = \"\"\n",
    "    with io.StringIO() as buf, redirect_stdout(buf):\n",
    "        model.print_summary(style=\"html\")\n",
    "        output = buf.getvalue()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#round counts in a way that the last digit become 0 or 5\n",
    "def round_five_mul(x, base=5):\n",
    "    return base * round(x/base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#function to process infection data \n",
    "def proc_infec_data(data, i):\n",
    "    datum = data\n",
    "    datum = datum[['age', 'age_cat', 'sex', 'flu_vaccine', 'smoking', 'bmi', 'imd', 'ethnicity', \n",
    "                   'region', 'CCI', 'died_date', 'deregistered_date', 'practice', \n",
    "                   'antibacterial_brit_'+str(i), 'ot_externa_date_'+str(i), 'ot_externa_ab_date_'+str(i), 'ot_externa_ab_type_'+str(i),\n",
    "                   'incdt_ot_externa_date_'+str(i), 'admitted_ot_externa_date_'+str(i), 'sgss_gp_cov_ot_externa_date_'+str(i)]]\n",
    "    \n",
    "    #drop rows with no ot_externa reord\n",
    "    datum = datum[datum['ot_externa_date_'+str(i)].notnull()]\n",
    "    #exclusion of covid positive 90 days before and 30 days after dx with ot_externa_i\n",
    "    datum = datum[datum['sgss_gp_cov_ot_externa_date_'+str(i)] == 0]\n",
    "    #rename variables with i\n",
    "    datum.rename(columns={'ot_externa_date_'+str(i): 'ot_externa_date', 'ot_externa_ab_date_'+str(i): 'ot_externa_ab_date', \n",
    "                           'ot_externa_ab_type_'+str(i): 'ab_type', 'antibacterial_brit_'+str(i): 'antibacterial_brit',\n",
    "                           'incdt_ot_externa_date_'+str(i): 'incdt_ot_externa_date', 'incdt_ot_externa_type_'+str(i): 'incdt_ot_externa_type',\n",
    "                           'admitted_ot_externa_date_'+str(i): 'admitted_ot_externa_date',\n",
    "                           'sgss_gp_cov_ot_externa_date_'+str(i): 'sgss_gp_cov_ot_externa_date'},\n",
    "                inplace=True)\n",
    "    \n",
    "    return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#summary table of baseline characteristics\n",
    "def make_summary_table(infection, infection_type, prob_pred):\n",
    "\n",
    "    #creating instance of one-hot-encoder with development data\n",
    "    enc = OneHotEncoder()\n",
    "    prob_pred_enc = pd.DataFrame(enc.fit_transform(prob_pred[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season', 'period']]).toarray())\n",
    "    prob_pred_enc.columns = enc.get_feature_names(prob_pred[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season', 'period']].columns)\n",
    "    #dataframe for lr and rf modelling \n",
    "    prob_pred = prob_pred.reset_index(drop=True)\n",
    "    prob_pred_enc_tot = pd.concat([prob_pred_enc, prob_pred[['antibacterial_brit']]], axis=1)\n",
    "\n",
    "    #calculate sums\n",
    "    summary_table = prob_pred_enc_tot.sum(axis=0).reset_index()\n",
    "    summary_table.columns = ['variable', 'count']\n",
    "    #round count to make last digit either 0 or 5\n",
    "    summary_table['mean'] = prob_pred_enc_tot.mean(axis=0).reset_index()[0]\n",
    "    summary_table['count'] = round_five_mul(summary_table['count'], base=5)\n",
    "    summary_table['std'] = prob_pred_enc_tot.std(axis=0).reset_index()[0]\n",
    "    #replace small counts (<=5) with 'SM'\n",
    "    summary_table.loc[(summary_table['count'] <= 5), 'count'] = 'SM'\n",
    "\n",
    "    #save table\n",
    "    summary_table.to_csv('../output/hospitalisation_prediction_'+infection+'/summary_table_'+infection+'_'+infection_type+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#summary table of baseline characteristics\n",
    "def make_summary_table_deciles(infection, infection_type, prob_pred_enc_lr_rf):\n",
    "    #calculate sums\n",
    "    summary_table = prob_pred_enc_lr_rf.sum(axis=0).reset_index()\n",
    "    summary_table.columns = ['variable', 'count']\n",
    "    #round count to make last digit either 0 or 5\n",
    "    summary_table['mean'] = prob_pred_enc_lr_rf.mean(axis=0).reset_index()[0]\n",
    "    summary_table['count'] = round_five_mul(summary_table['count'], base=5)\n",
    "    summary_table['std'] = prob_pred_enc_lr_rf.std(axis=0).reset_index()[0]\n",
    "    #replace small counts (<=5) with 'SM'\n",
    "    summary_table.loc[(summary_table['count'] <= 5), 'count'] = 'SM'\n",
    "\n",
    "    #save table\n",
    "    summary_table.to_csv('../output/hospitalisation_prediction_'+infection+'/summary_table_deciles_'+infection+'_'+infection_type+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def cox_build(infection, infection_type, data, data_no_abs):\n",
    "    #randomly splitting data into training (%75) and testing (%25)\n",
    "    data_dev, data_val = train_test_split(data_no_abs, test_size=0.25, random_state=42)\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(data_dev,\n",
    "            duration_col='duration_ot_externa_admitted',\n",
    "            event_col='event_ot_externa_admitted',\n",
    "            formula=\"age_cat + sex + CCI_cat + flu_vaccine + region + imd + ethnicity + smoking + season + bmi_cat + antibacterial_brit\")\n",
    "    cph.print_summary()\n",
    "\n",
    "    #save model output\n",
    "    output = GetPrintSummary(cph)\n",
    "    with open('../output/hospitalisation_prediction_'+infection+'/cph_'+infection+'_'+infection_type+'_summary.html', \"w\") as fo:\n",
    "        print(fo.write(output))\n",
    "        fo.close()\n",
    "\n",
    "    #save hazard ratios\n",
    "    covariates_betas = cph.hazard_ratios_.reset_index()\n",
    "    confidence_intervals = cph.confidence_intervals_.reset_index()\n",
    "    hrs = covariates_betas.merge(confidence_intervals, on='covariate', how='left')\n",
    "    hrs['95% lower-bound'] = np.exp(hrs['95% lower-bound'])\n",
    "    hrs['95% upper-bound'] = np.exp(hrs['95% upper-bound'])\n",
    "    hrs.covariate = hrs.covariate.str.replace(\"[\",\"\")\n",
    "    hrs.covariate = hrs.covariate.str.replace(\"]\",\"\")\n",
    "    hrs.covariate = hrs.covariate.str.replace(\"T.\",\"_\")\n",
    "    hrs.to_csv('../output/hospitalisation_prediction_'+infection+'/cph_'+infection+'_'+infection_type+'_hrs.csv', index=False)\n",
    "\n",
    "    ##add deciles of predicted risks and probability of prescribed antibiotics\n",
    "    #predict cumulative hazard in day 30 in train dataset\n",
    "    prob_pred = cph.predict_cumulative_hazard(data[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season', 'antibacterial_brit']]).loc[[30]].T\n",
    "    prob_pred.columns = ['pred']\n",
    "    #prob_pred_ot_externa_no_abs_incdt\n",
    "\n",
    "    #group cumulative hazard into 10 bins with equal frequency of observations in each bin\n",
    "    prob_pred['bins'] = pd.qcut(prob_pred['pred'], 10)\n",
    "    #prob_pred\n",
    "\n",
    "    ##add a columns of risk factors, prescribed antibiotics, and hosp event \n",
    "    prob_pred = pd.concat([prob_pred, data[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season', 'antibacterial_brit', 'ab_binary', 'event_'+infection+'_admitted']]], axis=1)\n",
    "    #prob_pred\n",
    "\n",
    "    ###needed for figures\n",
    "    #groupby bins to find mean predicted probability for each bin (pred_mean) and mean probability of being prescribed antibiotics (ab_prob_mean)\n",
    "    prob_pred_bin = prob_pred.groupby('bins')[['pred', 'ab_binary', 'event_'+infection+'_admitted']].agg(['mean', 'sum', 'count']).reset_index()\n",
    "    prob_pred_bin.columns = ['bins', 'pred_mean', 'pred_sum', 'pred_count', 'ab_prob_mean', 'ab_prob_sum', 'ab_prob_count', 'event_'+infection+'_admitted_mean', 'event_'+infection+'_admitted_sum', 'event_'+infection+'_admitted_count']\n",
    "    prob_pred_bin['bins'] = prob_pred_bin['bins'].astype(str)\n",
    "    #prob_pred_urti_no_abs_incdt_bin\n",
    "    prob_pred_bin.to_csv('../output/hospitalisation_prediction_'+infection+'/prob_pred_bin_'+infection+'_'+infection_type+'.csv', index=False)\n",
    "\n",
    "    #plot\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.lineplot(x='bins', y='ab_prob_mean', data=prob_pred_bin, marker='o', markersize=10)\n",
    "    g = sns.lineplot(x=\"bins\", data=prob_pred_bin, y=\"ab_prob_mean\", marker='*', linestyle='--', markersize=10)\n",
    "    plt.ylim(0)#, data.pred_mean_train.max() + data.pred_mean_train.max()/3)\n",
    "    plt.xlim(0)#, data.ab_prob_mean_train.max() + data.ab_prob_mean_train.max()/3)\n",
    "    plt.setp(g.collections, alpha=.5) #alpha for markers\n",
    "    plt.setp(g.lines, alpha=.5) #alpha for line\n",
    "    plt.xlabel('Decile', fontsize=14)\n",
    "    plt.ylabel('Mean probability of prescribing antibiotic', fontsize=14)\n",
    "    plt.gca().set_xticks(np.arange(0,10,1), minor=True)\n",
    "    plt.grid(b=True, which='major', color='k', linestyle=':', alpha=0.5)\n",
    "    plt.grid(which='minor', color='k', linestyle=':', alpha=0.5)\n",
    "    plt.xticks(prob_pred_bin.bins, rotation=90)\n",
    "    # plt.legend([],[], frameon=False)\n",
    "    # plt.savefig('../output/aggregate_ab_prob/aggregate_ab_prob_incdt.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    return prob_pred, prob_pred_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def lr_rf_build_risk_deciles(infection, infection_type, prob_pred):\n",
    "    ##data prep\n",
    "    prob_pred['bins'] = prob_pred['bins'].astype(str)\n",
    "\n",
    "    #save prob_pred for analysis in r\n",
    "    prob_pred.to_csv('../output/hospitalisation_prediction_'+infection+'/prob_pred_lr_rf_'+infection+'_'+infection_type+'_r_analysis.csv', index=False)\n",
    "\n",
    "    #creating instance of one-hot-encoder with development data\n",
    "    enc = OneHotEncoder()\n",
    "    prob_pred_enc = pd.DataFrame(enc.fit_transform(prob_pred[['bins']]).toarray())\n",
    "    prob_pred_enc.columns = enc.get_feature_names(prob_pred[['bins']].columns)\n",
    "    #drop 1st column to take it as reference group\n",
    "    prob_pred_enc = prob_pred_enc.iloc[: , 1:]\n",
    "    #dataframe for lr and rf modelling \n",
    "    prob_pred = prob_pred.reset_index(drop=True)\n",
    "    prob_pred_enc_lr_rf = pd.concat([prob_pred_enc, prob_pred[['ab_binary']]], axis=1)\n",
    "    #prob_pred_enc_lr_rf\n",
    "\n",
    "    #save prob_pred_enc_lr_rf for analysis in r\n",
    "    prob_pred_enc_lr_rf.to_csv('../output/hospitalisation_prediction_'+infection+'/prob_pred_lr_rf_'+infection+'_'+infection_type+'_r_analysis_binned.csv', index=False)\n",
    "\n",
    "    ##rf, lr modelling\n",
    "    #randomly splitting data into training (%75) and testing (%25)\n",
    "    data_enc_dev, data_enc_val = train_test_split(prob_pred_enc_lr_rf, test_size=0.25)\n",
    "    data_enc_dev_y = data_enc_dev[['ab_binary']]\n",
    "    data_enc_dev_x = data_enc_dev.drop('ab_binary', axis=1)\n",
    "    data_enc_val_y = data_enc_val[['ab_binary']]\n",
    "    data_enc_val_x = data_enc_val.drop('ab_binary', axis=1)\n",
    "\n",
    "    #building lr model\n",
    "    lr = LogisticRegression(solver=\"saga\", random_state=42).fit(data_enc_dev_x, data_enc_dev_y)\n",
    "    #predict probabilities of lr model\n",
    "    lr_pred_dev = lr.predict_proba(data_enc_dev_x)[:,1]\n",
    "    lr_pred_val = lr.predict_proba(data_enc_val_x)[:,1]\n",
    "\n",
    "    # ##building rf model\n",
    "    # rf = RandomForestClassifier()#n_estimators=500, max_leaf_nodes=50, max_depth=50)\n",
    "    # rf.fit(data_enc_dev_x, data_enc_dev_y)\n",
    "    # #predict probabilities to rf model\n",
    "    # rf_pred_dev = rf.predict_proba(data_enc_dev_x)[:,1]\n",
    "    # rf_pred_val = rf.predict_proba(data_enc_val_x)[:,1]\n",
    "\n",
    "    #calculate aurocs\n",
    "    auroc_lr_dev = sklearn.metrics.roc_auc_score(data_enc_dev_y, lr_pred_dev)\n",
    "    auroc_lr_val = sklearn.metrics.roc_auc_score(data_enc_val_y, lr_pred_val)\n",
    "    # auroc_rf_dev = roc_auc_score(data_enc_dev_y, rf_pred_dev)\n",
    "    # auroc_rf_val = roc_auc_score(data_enc_val_y, rf_pred_val)\n",
    "    #save and print aurocs\n",
    "    auroc_lr = pd.DataFrame([[auroc_lr_dev, auroc_lr_val]], columns=['auroc_dev', 'auroc_val'])\n",
    "    auroc_lr.to_csv('../output/hospitalisation_prediction_'+infection+'/auroc_lr_'+infection+'_'+infection_type+'.csv')\n",
    "    print('\\nAUROC of LR for deciles with development and validation data: %.5f'%(auroc_lr_dev), 'and %.5f' % (auroc_lr_val))\n",
    "    # print('AUROC of RF for deciles with development and validation data: %.5f'%(auroc_rf_dev), 'and %.5f' % (auroc_rf_val))\n",
    "\n",
    "    #caculate ORs and intervals of LR model, save and print them \n",
    "    # lr_coef = pd.DataFrame({\"or\": lr.coef_})#, \"Lower CI\": lr.conf_int()[0], \"Upper CI\": lr.conf_int()[1],})\n",
    "    # lr_coef_exp = np.exp(lr_coef)\n",
    "    # lr_coef_exp.to_csv('../output/hospitalisation_prediction_'+infection+'/coefs_lr_deciles_'+infection+'_'+infection_type+'.csv')\n",
    "    # lr_coef = lr.coef_\n",
    "    # print('LR ORs:\\n %s'%(lr_coef))\n",
    "    # lr_coef = pd.DataFrame(data=np.exp(lr.coef_), index=data_enc_dev_x.columns, columns=['lr_coef'])\n",
    "    # lr_coef = lr_coef.sort_values('lr_coef', ascending=False)\n",
    "    # lr_coef = pd.DataFrame(data=lr.coef_.T, index=data_enc_dev_x.columns, columns=['lr_coef'])#.sort_values(by=['feature_importance'], ascending=False)\n",
    "    # # lr_coef['lr_coef_lower_bound'] = st.norm.ppf(lr_coef['lr_coef'])\n",
    "    # alpha = 0.05\n",
    "    # #the coefficients of the regression model\n",
    "    # coefs = np.r_[lr.coef_.T.tolist()]#[lr.intercept_], lr.coef_.T.tolist()\n",
    "    # #build an auxiliary dataframe with the constant term in it\n",
    "    # X_aux = data_enc_dev_x.copy()\n",
    "    # # X_aux.insert(0, 'const', 1)\n",
    "    # #degrees of freedom\n",
    "    # dof = -np.diff(X_aux.shape)[0]\n",
    "    # #Student's t-distribution table lookup\n",
    "    # t_val = stats.t.isf(alpha/2, dof)\n",
    "    # #MSE of the residuals\n",
    "    # mse = np.sum((data_enc_dev_y['ab_binary'].to_numpy() - lr.predict(data_enc_dev_x)) ** 2) / dof\n",
    "    # #inverse of the variance of the parameters\n",
    "    # var_params = np.diag(np.linalg.inv(X_aux.T.dot(X_aux)))\n",
    "    # #distance between lower and upper bound of CI\n",
    "    # gap = t_val * np.sqrt(mse * var_params)\n",
    "    # lr_coef_ors_ints = pd.DataFrame({'coef': coefs.ravel(), 'coef_lower': coefs.ravel() - gap, 'coef_upper': coefs.ravel() + gap}, index=X_aux.columns)\n",
    "    # lr_coef_ors_ints[['ors', 'ors_lower', 'ors_upper']] = np.exp(lr_coef_ors_ints[['coef', 'coef_lower', 'coef_upper']])\n",
    "    # # lr_coef_ors_ints = lr_coef_ors_ints.sort_values('coef', ascending=False)\n",
    "    # lr_coef_ors_ints.to_csv('../output/hospitalisation_prediction_'+infection+'/ors_lr_'+infection+'_'+infection_type+'.csv')\n",
    "    lr_summary = get_lr_betas_intervals(data_enc_dev)\n",
    "    lr_summary.to_csv('../output/hospitalisation_prediction_'+infection+'/ors_lr_'+infection+'_'+infection_type+'.csv')\n",
    "    print('LR summary:\\n %s'%(lr_summary))\n",
    "\n",
    "    #print parameters of grid search\n",
    "    # print(\"\\nRF parameters after grid search:\", rf)\n",
    "\n",
    "    # #print feature importance of RF model\n",
    "    # rf_coef = pd.DataFrame(data=rf.feature_importances_, index=data_enc_dev_x.columns, columns=['rf_coef'])#.sort_values(by=['feature_importance'], ascending=False)\n",
    "    # rf_coef = rf_coef.sort_values('rf_coef', ascending=False)\n",
    "    # rf_coef.to_csv('../output/hospitalisation_prediction_'+infection+'/coefs_rf_deciles_'+infection+'_'+infection_type+'.csv')\n",
    "    # print('\\nRF feature importance:\\n %s'%(rf_coef))\n",
    "\n",
    "    #plot roc curves\n",
    "    r_fpr_lr_dev, r_tpr_lr_dev, _ = roc_curve(data_enc_dev_y, lr_pred_dev)\n",
    "    r_fpr_lr_val, r_tpr_lr_val, _ = roc_curve(data_enc_val_y, lr_pred_val)\n",
    "    # r_fpr_rf_dev, r_tpr_rf_dev, _ = roc_curve(data_enc_dev_y, rf_pred_dev)\n",
    "    # r_fpr_rf_val, r_tpr_rf_val, _ = roc_curve(data_enc_val_y, rf_pred_val)\n",
    "\n",
    "    fig, ax1 = pyplot.subplots(figsize=(7, 7))\n",
    "    line_lr_dev, = plt.plot(r_fpr_lr_dev, r_tpr_lr_dev, linestyle='-', marker='o', markersize=6, markevery=0.1, color='#408678', label='LR with development data')\n",
    "    line_lr_val, = plt.plot(r_fpr_lr_val, r_tpr_lr_val, linestyle='--', marker='v', markersize=6, markevery=0.1, color='#6ce0c9', label='LR with validation data')\n",
    "    # line_rf_dev, = plt.plot(r_fpr_rf_dev, r_tpr_rf_dev, linestyle='-', marker='o', markersize=6, markevery=0.1, color='#8D576D', label='RF with development data')\n",
    "    # line_rf_val, = plt.plot(r_fpr_rf_val, r_tpr_rf_val, linestyle='--', marker='v', markersize=6, markevery=0.1, color='#eb91b7', label='RF with validation data')\n",
    "    \n",
    "    squares = [0,1.01] \n",
    "    plt.plot(squares,linewidth=1, color='grey')\n",
    "    plt.ylim(0,1.01)\n",
    "    plt.xlim(0,1)\n",
    "    plt.xlabel('Specificity', fontsize=14)\n",
    "    plt.ylabel('Sensitivity', fontsize=14)\n",
    "    \n",
    "    #reversing xticks\n",
    "    xticks = [1.0, 0.8, 0.6, 0.4, 0.2, 0.0]\n",
    "    x = np.arange(len(xticks))\n",
    "    ax1.set(xticklabels=xticks)\n",
    "    ax1.legend(fontsize=10)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10, rotation=0)\n",
    "    plt.title(\"ROC curve of LR model with deciles\", fontsize=14)\n",
    "    plt.savefig('../output/hospitalisation_prediction_'+infection+'/roc_deciles_'+infection+'_'+infection_type+'.jpg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return prob_pred_enc_lr_rf, data_enc_dev, data_enc_val, lr_pred_dev, lr_pred_val#, rf_pred_dev, rf_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def lr_rf_build_risk_riskfactors(infection, infection_type, prob_pred):\n",
    "    ##data prep\n",
    "    prob_pred['bins'] = prob_pred['bins'].astype(str)\n",
    "    #creating instance of one-hot-encoder with development data\n",
    "    enc = OneHotEncoder()\n",
    "    prob_pred_enc = pd.DataFrame(enc.fit_transform(prob_pred[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season']]).toarray())\n",
    "    prob_pred_enc.columns = enc.get_feature_names(prob_pred[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season']].columns)\n",
    "    #drop ref columns\n",
    "    prob_pred_enc = prob_pred_enc[['age_cat_25_34', 'age_cat_35_44', 'age_cat_45_54', 'age_cat_55_64', 'age_cat_65_74', 'age_cat_75_more', #'age_cat_15_24', \n",
    "                                   'sex_male', #'sex_female', \n",
    "                                   'CCI_cat_high', 'CCI_cat_low', 'CCI_cat_medium', 'CCI_cat_very_high', #'CCI_cat_very_low', \n",
    "                                   'flu_vaccine_yes', #'flu_vaccine_no',\n",
    "                                   'bmi_cat_obese', 'bmi_cat_overweight', 'bmi_cat_underweight', 'bmi_cat_unknown', #'bmi_cat_healthy_weight',\n",
    "                                   'region_yorkshire', 'region_east_midlands', 'region_london', 'region_north_east', 'region_north_west', 'region_south_east', 'region_south_west', 'region_west_midlands', #'region_east', \n",
    "                                   'imd_very_unaffluent', 'imd_medium', 'imd_affluent', 'imd_very_affluent', 'imd_unknown', #'imd_unaffluent',\n",
    "                                   'ethnicity_asian', 'ethnicity_other', 'ethnicity_unknown', 'ethnicity_mixed', 'ethnicity_black', #'ethnicity_white', \n",
    "                                   'smoking_smoker', 'smoking_never_smoked', 'smoking_unknown', #'smoking_ex_smoker', \n",
    "                                   'season_spring', 'season_summer', 'season_winter', #'season_autumn',\n",
    "                                   ]]\n",
    "    #dataframe for lr and rf modelling \n",
    "    prob_pred = prob_pred.reset_index(drop=True)\n",
    "    prob_pred_enc_lr_rf = pd.concat([prob_pred_enc, prob_pred[['antibacterial_brit', 'ab_binary']]], axis=1)\n",
    "    #prob_pred_enc_lr_rf\n",
    "\n",
    "    ##rf, lr modelling\n",
    "    #randomly splitting data into training (%75) and testing (%25)\n",
    "    data_enc_dev, data_enc_val = train_test_split(prob_pred_enc_lr_rf, test_size=0.25)\n",
    "    data_enc_dev_y = data_enc_dev[['ab_binary']]\n",
    "    data_enc_dev_x = data_enc_dev.drop('ab_binary', axis=1)\n",
    "    data_enc_val_y = data_enc_val[['ab_binary']]\n",
    "    data_enc_val_x = data_enc_val.drop('ab_binary', axis=1)\n",
    "\n",
    "    #building lr model\n",
    "    lr = LogisticRegression(solver=\"saga\", random_state=42).fit(data_enc_dev_x, data_enc_dev_y)\n",
    "    #predict probabilities of lr model\n",
    "    lr_pred_dev = lr.predict_proba(data_enc_dev_x)[:,1]\n",
    "    lr_pred_val = lr.predict_proba(data_enc_val_x)[:,1]\n",
    "\n",
    "    # ##building rf model\n",
    "    # rf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, max_depth=50)\n",
    "    # rf.fit(data_enc_dev_x, data_enc_dev_y)\n",
    "    # #predict probabilities to rf model\n",
    "    # rf_pred_dev = rf.predict_proba(data_enc_dev_x)[:,1]\n",
    "    # rf_pred_val = rf.predict_proba(data_enc_val_x)[:,1]\n",
    "\n",
    "    #print aurocs\n",
    "    auroc_lr_dev = sklearn.metrics.roc_auc_score(data_enc_dev_y, lr_pred_dev)\n",
    "    auroc_lr_val = sklearn.metrics.roc_auc_score(data_enc_val_y, lr_pred_val)\n",
    "    # auroc_rf_dev = roc_auc_score(data_enc_dev_y, rf_pred_dev)\n",
    "    # auroc_rf_val = roc_auc_score(data_enc_val_y, rf_pred_val)\n",
    "    print('\\nAUROC of LR for risk factors with development and validation data: %.5f'%(auroc_lr_dev), 'and %.5f' % (auroc_lr_val))\n",
    "    # print('AUROC of RF for risk factors with development and validation data: %.5f'%(auroc_rf_dev), 'and %.5f' % (auroc_rf_val))\n",
    "\n",
    "    # #print summary of LR model\n",
    "    # lr_coef = pd.DataFrame({\"OR\": lr.params, \"Lower CI\": lr.conf_int()[0], \"Upper CI\": lr.conf_int()[1],})\n",
    "    # lr_coef = np.exp(lr_coef)\n",
    "    # lr_coef.to_csv('../output/hospitalisation_prediction_'+infection+'/coefs_lr_'+infection+'_'+infection_type+'.csv')\n",
    "    # print('LR coefficients:\\n %s'%(lr_coef))\n",
    "    \n",
    "#     alpha = 0.05\n",
    "#     #the coefficients of the regression model\n",
    "#     coefs = np.r_[lr.coef_.T.tolist()] #[lr.intercept_], lr.coef_.T.tolist()\n",
    "#     #build an auxiliary dataframe with the constant term in it\n",
    "#     X_aux = data_enc_dev_x.copy()\n",
    "#    #  X_aux.insert(0, 'const', 1)\n",
    "#     #degrees of freedom\n",
    "#     dof = -np.diff(X_aux.shape)[0]\n",
    "#     #Student's t-distribution table lookup\n",
    "#     t_val = stats.t.isf(alpha/2, dof)\n",
    "#     #MSE of the residuals\n",
    "#     mse = np.sum((data_enc_dev_y['ab_binary'].to_numpy() - lr.predict(data_enc_dev_x)) ** 2) / dof\n",
    "#     #inverse of the variance of the parameters\n",
    "#     var_params = np.diag(np.linalg.inv(X_aux.T.dot(X_aux)))\n",
    "#     #distance between lower and upper bound of CI\n",
    "#     gap = t_val * np.sqrt(mse * var_params)\n",
    "#     lr_coef_ors_ints = pd.DataFrame({'coef': coefs.ravel(), 'coef_lower': coefs.ravel() - gap, 'coef_upper': coefs.ravel() + gap}, index=X_aux.columns)\n",
    "#     lr_coef_ors_ints[['ors', 'ors_lower', 'ors_upper']] = np.exp(lr_coef_ors_ints[['coef', 'coef_lower', 'coef_upper']])\n",
    "#     # lr_coef_ors_ints = lr_coef_ors_ints.sort_values('coef', ascending=False)\n",
    "#     lr_coef_ors_ints.to_csv('../output/hospitalisation_prediction_'+infection+'/ors_lr_'+infection+'_'+infection_type+'.csv')\n",
    "    lr_summary = get_lr_betas_intervals(data_enc_dev)\n",
    "    lr_summary.to_csv('../output/hospitalisation_prediction_'+infection+'/ors_lr_'+infection+'_'+infection_type+'.csv')\n",
    "    print('LR summary:\\n %s'%(lr_summary))\n",
    "\n",
    "    #print parameters of grid search\n",
    "    # print(\"\\nRF parameters after grid search:\", rf)\n",
    "\n",
    "    # #print feature importance of RF model\n",
    "    # rf_coef = pd.DataFrame(data=rf.feature_importances_, index=data_enc_dev_x.columns, columns=['rf_coef'])#.sort_values(by=['feature_importance'], ascending=False)\n",
    "    # rf_coef = rf_coef.sort_values('rf_coef', ascending=False)\n",
    "    # lr_coef.to_csv('../output/hospitalisation_prediction_'+infection+'/coefs_rf_'+infection+'_'+infection_type+'.csv')\n",
    "    # print('\\nRF feature importance:\\n %s'%(rf_coef))\n",
    "\n",
    "    #plot roc curves\n",
    "    r_fpr_lr_dev, r_tpr_lr_dev, _ = roc_curve(data_enc_dev_y, lr_pred_dev)\n",
    "    r_fpr_lr_val, r_tpr_lr_val, _ = roc_curve(data_enc_val_y, lr_pred_val)\n",
    "    # r_fpr_rf_dev, r_tpr_rf_dev, _ = roc_curve(data_enc_dev_y, rf_pred_dev)\n",
    "    # r_fpr_rf_val, r_tpr_rf_val, _ = roc_curve(data_enc_val_y, rf_pred_val)\n",
    "\n",
    "    fig, ax1 = pyplot.subplots(figsize=(7, 7))\n",
    "    line_lr_dev, = plt.plot(r_fpr_lr_dev, r_tpr_lr_dev, linestyle='-', marker='o', markersize=6, markevery=0.1, color='#408678', label='LR with development data')\n",
    "    line_lr_val, = plt.plot(r_fpr_lr_val, r_tpr_lr_val, linestyle='--', marker='v', markersize=6, markevery=0.1, color='#6ce0c9', label='LR with validation data')\n",
    "    # line_rf_dev, = plt.plot(r_fpr_rf_dev, r_tpr_rf_dev, linestyle='-', marker='o', markersize=6, markevery=0.1, color='#8D576D', label='RF with development data')\n",
    "    # line_rf_val, = plt.plot(r_fpr_rf_val, r_tpr_rf_val, linestyle='--', marker='v', markersize=6, markevery=0.1, color='#eb91b7', label='RF with validation data')\n",
    "    \n",
    "    squares = [0,1.01] \n",
    "    plt.plot(squares,linewidth=1, color='grey')\n",
    "    plt.ylim(0,1.01)\n",
    "    plt.xlim(0,1)\n",
    "    plt.xlabel('Specificity', fontsize=14)\n",
    "    plt.ylabel('Sensitivity', fontsize=14)\n",
    "    \n",
    "    #reversing xticks\n",
    "    xticks = [1.0, 0.8, 0.6, 0.4, 0.2, 0.0]\n",
    "    x = np.arange(len(xticks))\n",
    "    ax1.set(xticklabels=xticks)\n",
    "    ax1.legend(fontsize=10)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10, rotation=0)\n",
    "    plt.title(\"ROC curve of LR and RF models with risk factors\", fontsize=14)\n",
    "    plt.savefig('../output/hospitalisation_prediction_'+infection+'/roc_riskfactors_'+infection+'_'+infection_type+'.jpg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return prob_pred_enc_lr_rf, data_enc_dev, data_enc_val, lr_pred_dev, lr_pred_val#, rf_pred_dev, rf_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#bootstrap and create lr models\n",
    "def lr_bootstrap(data):\n",
    "    sample = data.sample(data.shape[0], replace=True)\n",
    "    X_tr = sample[[c for c in sample.columns if c != 'ab_binary']]\n",
    "    y_tr = sample.ab_binary\n",
    "    lr = LogisticRegression().fit(X_tr, y_tr)\n",
    "    params = list(lr.coef_[0]) \n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#calculate mean and standard error of lr models with bootstraped data to calculate mean coeffients and intervals of coefficients and odds ratios and their intervals\n",
    "def get_lr_betas_intervals(data):\n",
    "    #get column names of inputs\n",
    "    data_x_columns = data.drop('ab_binary', axis=1).columns\n",
    "    #create lr models with bootstraped samples for 100 times\n",
    "    params_samples = pd.DataFrame([lr_bootstrap(data) for _ in range(100)])\n",
    "    #calculate mean and standard error for coefficients of lrs with samples\n",
    "    coefs_mean = params_samples.mean()\n",
    "    coefs_se = params_samples.std()\n",
    "    z_val = stats.norm.ppf(0.975)\n",
    "    coefs_se_z_val = coefs_se * z_val\n",
    "    #create a table of coefficients and their intervals for covariates \n",
    "    lr_summary = pd.DataFrame({'covariate': data_x_columns.tolist(), 'coef': coefs_mean, 'coef_lower_95%': coefs_mean - coefs_se_z_val, 'coef_upper_95%': coefs_mean + coefs_se_z_val})\n",
    "    #clculate odds ratios and their intervals for covariates\n",
    "    lr_summary[['or', 'or_lower_95%', 'or_upper_95%']] = np.exp(lr_summary[['coef', 'coef_lower_95%', 'coef_upper_95%']])\n",
    "\n",
    "    return lr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def calibration_rf_lr(infection, infection_type, data_enc_dev, data_enc_val, lr_pred_dev, lr_pred_val):#, rf_pred_dev, rf_pred_val):\n",
    "    # ##calibration for RF\n",
    "    # rf_prob_pred_dev = pd.DataFrame(data=rf_pred_dev, columns=['pred'])\n",
    "    # #group cumulative hazard into 10 bins with equal frequency of observations in each bin\n",
    "    # rf_prob_pred_dev['bins'] = pd.qcut(rf_prob_pred_dev['pred'], 10, duplicates=\"drop\")\n",
    "    # #merge cumulative hazards with their actual events (0, 1)\n",
    "    # rf_prob_pred_dev = pd.merge(rf_prob_pred_dev, data_enc_dev['ab_binary'], left_index=True, right_index=True)\n",
    "    # #groupby bins to find mean predicted probability for each bin (pred_mean), count of events in each bin (event_sum) and count of samples in each bin (event_count)\n",
    "    # rf_prob_pred_dev_groupby_bin = rf_prob_pred_dev.groupby('bins')[['pred', 'ab_binary']].agg(['mean', 'sum', 'count']).reset_index()\n",
    "    # rf_prob_pred_dev_groupby_bin.columns = ['bins', 'pred_mean', 'pred_sum', 'pred_count', 'ab_binary_mean', 'ab_binary_sum', 'ab_binary_count']\n",
    "    # #calculate proportion of events in each bin\n",
    "    # rf_prob_pred_dev_groupby_bin['ab_binary_proportion'] = rf_prob_pred_dev_groupby_bin['ab_binary_sum']/rf_prob_pred_dev_groupby_bin['ab_binary_count']\n",
    "    # #\n",
    "    # rf_prob_pred_val = pd.DataFrame(data=rf_pred_val, columns=['pred'])\n",
    "    # #group cumulative hazard into 10 bins with equal frequency of observations in each bin\n",
    "    # rf_prob_pred_val['bins'] = pd.qcut(rf_prob_pred_val['pred'], 10, duplicates=\"drop\")\n",
    "    # #merge cumulative hazards with their actual events (0, 1)\n",
    "    # rf_prob_pred_val = pd.merge(rf_prob_pred_val, data_enc_val['ab_binary'], left_index=True, right_index=True)\n",
    "    # #groupby bins to find mean predicted probability for each bin (pred_mean), count of events in each bin (event_sum) and count of samples in each bin (event_count)\n",
    "    # rf_prob_pred_val_groupby_bin = rf_prob_pred_val.groupby('bins')[['pred', 'ab_binary']].agg(['mean', 'sum', 'count']).reset_index()\n",
    "    # rf_prob_pred_val_groupby_bin.columns = ['bins', 'pred_mean', 'pred_sum', 'pred_count', 'ab_binary_mean', 'ab_binary_sum', 'ab_binary_count']\n",
    "    # #calculate proportion of events in each bin\n",
    "    # rf_prob_pred_val_groupby_bin['ab_binary_proportion'] = rf_prob_pred_val_groupby_bin['ab_binary_sum']/rf_prob_pred_val_groupby_bin['ab_binary_count']\n",
    "    # #plot calibration plot for RF model with development and validation data\n",
    "    # fig, ax1 = plt.subplots(figsize=(7, 7))\n",
    "    # plt.plot(rf_prob_pred_dev_groupby_bin.pred_mean, rf_prob_pred_dev_groupby_bin['ab_binary_proportion'], color='#8D576D', linestyle='solid', marker='o', alpha=0.9)\n",
    "    # plt.plot(rf_prob_pred_val_groupby_bin.pred_mean, rf_prob_pred_val_groupby_bin['ab_binary_proportion'], color='#eb91b7', linestyle='dashed', marker='v', alpha=0.9)\n",
    "    # plt.xlabel('Mean predicted probabilities', fontsize=14)\n",
    "    # plt.ylabel('Proportion of observed values', fontsize=14)\n",
    "    # plt.xticks(fontsize=12)\n",
    "    # plt.yticks(fontsize=12, rotation=0)\n",
    "    # plt.xlim(0, max(rf_prob_pred_dev_groupby_bin.pred_mean.max(), rf_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2) + (max(rf_prob_pred_dev_groupby_bin.pred_mean.max(), rf_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2)/3))\n",
    "    # plt.ylim(0, max(rf_prob_pred_dev_groupby_bin.pred_mean.max(), rf_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2) + (max(rf_prob_pred_dev_groupby_bin.pred_mean.max(), rf_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2)/3))\n",
    "    # plt.plot([0, 1], [0, 1], linewidth=1, linestyle='-', color='grey')\n",
    "    # plt.title(\"Calibration plot of RF model\", fontsize=14)\n",
    "    # legend_dev = mlines.Line2D([], [], color='#8D576D', linestyle='-', marker='o', markersize=10, label='Development data', alpha=.9)\n",
    "    # legend_val = mlines.Line2D([], [], color='#eb91b7', linestyle='--', marker='v', markersize=10, label='Validation data', alpha=.9)\n",
    "    # plt.legend(handles=[legend_dev, legend_val])\n",
    "    # plt.savefig('../output/hospitalisation_prediction_'+infection+'/calib_rf_'+infection+'_'+infection_type+'.jpg', bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "    ##calibration for LR\n",
    "    lr_prob_pred_dev = pd.DataFrame(data=lr_pred_dev, columns=['pred'])\n",
    "    #group cumulative hazard into 10 bins with equal frequency of observations in each bin\n",
    "    lr_prob_pred_dev['bins'] = pd.qcut(lr_prob_pred_dev['pred'], 10, duplicates=\"drop\")\n",
    "    #merge cumulative hazards with their actual events (0, 1)\n",
    "    lr_prob_pred_dev = pd.merge(lr_prob_pred_dev, data_enc_dev['ab_binary'], left_index=True, right_index=True)\n",
    "    #groupby bins to find mean predicted probability for each bin (pred_mean), count of events in each bin (event_sum) and count of samples in each bin (event_count)\n",
    "    lr_prob_pred_dev_groupby_bin = lr_prob_pred_dev.groupby('bins')[['pred', 'ab_binary']].agg(['mean', 'sum', 'count']).reset_index()\n",
    "    lr_prob_pred_dev_groupby_bin.columns = ['bins', 'pred_mean', 'pred_sum', 'pred_count', 'ab_binary_mean', 'ab_binary_sum', 'ab_binary_count']\n",
    "    #calculate proportion of events in each bin\n",
    "    lr_prob_pred_dev_groupby_bin['ab_binary_proportion'] = lr_prob_pred_dev_groupby_bin['ab_binary_sum']/lr_prob_pred_dev_groupby_bin['ab_binary_count']\n",
    "    #\n",
    "    lr_prob_pred_val = pd.DataFrame(data=lr_pred_val, columns=['pred'])\n",
    "    #group cumulative hazard into 10 bins with equal frequency of observations in each bin\n",
    "    lr_prob_pred_val['bins'] = pd.qcut(lr_prob_pred_val['pred'], 10, duplicates=\"drop\")\n",
    "    #merge cumulative hazards with their actual events (0, 1)\n",
    "    lr_prob_pred_val = pd.merge(lr_prob_pred_val, data_enc_val['ab_binary'], left_index=True, right_index=True)\n",
    "    #groupby bins to find mean predicted probability for each bin (pred_mean), count of events in each bin (event_sum) and count of samples in each bin (event_count)\n",
    "    lr_prob_pred_val_groupby_bin = lr_prob_pred_val.groupby('bins')[['pred', 'ab_binary']].agg(['mean', 'sum', 'count']).reset_index()\n",
    "    lr_prob_pred_val_groupby_bin.columns = ['bins', 'pred_mean', 'pred_sum', 'pred_count', 'ab_binary_mean', 'ab_binary_sum', 'ab_binary_count']\n",
    "    #calculate proportion of events in each bin\n",
    "    lr_prob_pred_val_groupby_bin['ab_binary_proportion'] = lr_prob_pred_val_groupby_bin['ab_binary_sum']/lr_prob_pred_val_groupby_bin['ab_binary_count']\n",
    "    #plot calibration plot for RF model with development and validation data\n",
    "    fig, ax1 = plt.subplots(figsize=(7, 7))\n",
    "    plt.plot(lr_prob_pred_dev_groupby_bin.pred_mean, lr_prob_pred_dev_groupby_bin['ab_binary_proportion'], color='#408678', linestyle='solid', marker='o', alpha=0.9)\n",
    "    plt.plot(lr_prob_pred_val_groupby_bin.pred_mean, lr_prob_pred_val_groupby_bin['ab_binary_proportion'], color='#6ce0c9', linestyle='dashed', marker='v', alpha=0.6)\n",
    "    plt.xlabel('Mean predicted probabilities', fontsize=14)\n",
    "    plt.ylabel('Proportion of observed values', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12, rotation=0)\n",
    "    plt.xlim(0, max(lr_prob_pred_dev_groupby_bin.pred_mean.max(), lr_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2) + (max(lr_prob_pred_dev_groupby_bin.pred_mean.max(), lr_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2)/3))\n",
    "    plt.ylim(0, max(lr_prob_pred_dev_groupby_bin.pred_mean.max(), lr_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2) + (max(lr_prob_pred_dev_groupby_bin.pred_mean.max(), lr_prob_pred_dev_groupby_bin['ab_binary_proportion'].max()).round(decimals = 2)/3))\n",
    "    plt.plot([0, 1], [0, 1], linewidth=1, linestyle='-', color='grey')\n",
    "    plt.title(\"Calibration plot of LR model\", fontsize=14)\n",
    "    legend_dev = mlines.Line2D([], [], color='#408678', linestyle='-', marker='o', markersize=10, label='Development data', alpha=.9)\n",
    "    legend_val = mlines.Line2D([], [], color='#6ce0c9', linestyle='--', marker='v', markersize=10, label='Validation data', alpha=.6)\n",
    "    plt.legend(handles=[legend_dev, legend_val])\n",
    "    plt.savefig('../output/hospitalisation_prediction_'+infection+'/calib_lr_'+infection+'_'+infection_type+'.jpg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#read data\n",
    "data = pd.read_csv(f'../output/hospitalisation_data/input_hospitalisation_ot_externa.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#calculate Chalrson comorbidity index (CCI)\n",
    "data['CCI'] = np.nan\n",
    "\n",
    "for idx, x in enumerate(data['CCI']):\n",
    "    n=0\n",
    "    if data.iat[idx, data.columns.get_loc('mi_comor')] == 1: \n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('cardiovascular_comor')] == 1: \n",
    "        n=n+1 \n",
    "    if data.iat[idx, data.columns.get_loc('peripheral_vascular_comor')] == 1: \n",
    "        n=n+1 \n",
    "    if data.iat[idx, data.columns.get_loc('chronic_obstructive_pulmonary_comor')] == 1: \n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('diabetes_comor')] == 1: \n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('dementia_comor')] == 1: \n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('peptic_ulcer_comor')] == 1:\n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('connective_tissue_comor')] == 1:\n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('mild_liver_comor')] == 1: \n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('heart_failure_comor')] == 1: \n",
    "        n=n+1\n",
    "    if data.iat[idx, data.columns.get_loc('hemiplegia_comor')] == 1: \n",
    "        n=n+2\n",
    "    if data.iat[idx, data.columns.get_loc('mod_severe_renal_comor')] == 1:\n",
    "        n=n+2\n",
    "    if data.iat[idx, data.columns.get_loc('diabetes_complications_comor')] == 1:\n",
    "        n=n+2\n",
    "    if data.iat[idx, data.columns.get_loc('cancer_comor')] == 1:\n",
    "        n=n+2\n",
    "    if data.iat[idx, data.columns.get_loc('mod_severe_liver_comor')] == 1:\n",
    "        n=n+3\n",
    "    if data.iat[idx, data.columns.get_loc('metastatic_cancer_comor')] == 1:\n",
    "        n=n+6\n",
    "    if data.iat[idx, data.columns.get_loc('hiv_comor')] == 1:\n",
    "        n=n+6\n",
    "    \n",
    "    data.iat[idx, data.columns.get_loc('CCI')]=n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- data preparation\n",
    "\n",
    "### 2-1- gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#process 20 ot_externas and concatenate them \n",
    "data_ot_externa_1 = proc_infec_data(data,1)\n",
    "data_ot_externa_2 = proc_infec_data(data,2)\n",
    "data_ot_externa_3 = proc_infec_data(data,3)\n",
    "data_ot_externa_4 = proc_infec_data(data,4)\n",
    "data_ot_externa_5 = proc_infec_data(data,5)\n",
    "data_ot_externa_6 = proc_infec_data(data,6)\n",
    "data_ot_externa_7 = proc_infec_data(data,7)\n",
    "data_ot_externa_8 = proc_infec_data(data,8)\n",
    "data_ot_externa_9 = proc_infec_data(data,9)\n",
    "data_ot_externa_10 = proc_infec_data(data,10)\n",
    "data_ot_externa_11 = proc_infec_data(data,11)\n",
    "data_ot_externa_12 = proc_infec_data(data,12)\n",
    "data_ot_externa_13 = proc_infec_data(data,13)\n",
    "data_ot_externa_14 = proc_infec_data(data,14)\n",
    "data_ot_externa_15 = proc_infec_data(data,15)\n",
    "data_ot_externa_16 = proc_infec_data(data,16)\n",
    "data_ot_externa_17 = proc_infec_data(data,17)\n",
    "data_ot_externa_18 = proc_infec_data(data,18)\n",
    "data_ot_externa_19 = proc_infec_data(data,19)\n",
    "data_ot_externa_20 = proc_infec_data(data,20)\n",
    "\n",
    "data_ot_externa = pd.concat([data_ot_externa_1, data_ot_externa_2, data_ot_externa_3, data_ot_externa_4, data_ot_externa_5, data_ot_externa_6, data_ot_externa_7, data_ot_externa_8, data_ot_externa_9, data_ot_externa_10, data_ot_externa_11, data_ot_externa_12, data_ot_externa_13, data_ot_externa_14, data_ot_externa_15, data_ot_externa_16, data_ot_externa_17, data_ot_externa_18, data_ot_externa_19, data_ot_externa_20])\n",
    "data_ot_externa.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2- add season, event, and duration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##add variable season\n",
    "#convert data types\n",
    "data_ot_externa['ot_externa_date'] = data_ot_externa['ot_externa_date'].astype('datetime64[ns]')\n",
    "data_ot_externa['admitted_ot_externa_date'] = data_ot_externa['admitted_ot_externa_date'].astype('datetime64[ns]')\n",
    "data_ot_externa.died_date = data_ot_externa.died_date.astype('datetime64[ns]')\n",
    "data_ot_externa.deregistered_date = data_ot_externa.deregistered_date.astype('datetime64[ns]')\n",
    "\n",
    "#add a variable called date using gp consultation dates\n",
    "data_ot_externa['date'] = data_ot_externa['ot_externa_date'] \n",
    "data_ot_externa['date'] = data_ot_externa['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "#get today's date in year and month\n",
    "today_date_y_m = date.today()\n",
    "today_date_y_m = today_date_y_m.strftime('%Y-%m')\n",
    "\n",
    "#drop any records of data_ot_externa with today's date in year and month\n",
    "data_ot_externa = data_ot_externa[data_ot_externa['date'] != today_date_y_m]\n",
    "\n",
    "#get two months before today's date in year and month \n",
    "last_1_month_date_y_m = date.today() - pd.DateOffset(months=1)\n",
    "last_1_month_date_y_m = last_1_month_date_y_m.strftime('%Y-%m')\n",
    "last_2_month_date_y_m = date.today() - pd.DateOffset(months=2)\n",
    "last_2_month_date_y_m = last_2_month_date_y_m.strftime('%Y-%m')\n",
    "#drop any record of data with two month before today's date in year and month\n",
    "data_ot_externa = data_ot_externa[data_ot_externa['date'] != last_1_month_date_y_m]\n",
    "data_ot_externa = data_ot_externa[data_ot_externa['date'] != last_2_month_date_y_m]\n",
    "\n",
    "#add a variable called season based on the month of ot_externa records\n",
    "data_ot_externa['season'] = np.nan\n",
    "data_ot_externa['date_month'] = pd.DatetimeIndex(data_ot_externa['date']).month\n",
    "\n",
    "conditions = [\n",
    "    (data_ot_externa['date_month'] >= 3) & (data_ot_externa['date_month'] <= 5),\n",
    "    (data_ot_externa['date_month'] >= 6) & (data_ot_externa['date_month'] <= 8),\n",
    "    (data_ot_externa['date_month'] >= 9) & (data_ot_externa['date_month'] <= 11),]\n",
    "choices = ['spring', 'summer', 'autumn']\n",
    "data_ot_externa['season'] = np.select(conditions, choices, default='winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#add variable time period\n",
    "data_ot_externa.loc[(data_ot_externa['date'] <= '2019-12'), 'period'] = 'prepandemic'\n",
    "data_ot_externa.loc[((data_ot_externa['date'] >= '2020-05') & (data_ot_externa['date'] <= '2021-04')), 'period'] = 'during_pandemic'\n",
    "data_ot_externa.loc[(data_ot_externa['date'] >= '2021-05'), 'period'] = 'post_2nd_lockdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_ot_externa['date'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### event and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#scenario 1\n",
    "#not hosped (nothing happened)\n",
    "data_ot_externa.loc[data_ot_externa['admitted_ot_externa_date'].isnull(), 'event_ot_externa_admitted'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#scenario 2 \n",
    "#become a case (uncensoring)\n",
    "#calculating days between infection gp consultation and hosp\n",
    "data_ot_externa['delta_ot_externa_admitted'] = (data_ot_externa['admitted_ot_externa_date'] - data_ot_externa['ot_externa_date']).dt.days\n",
    "data_ot_externa.loc[((data_ot_externa['delta_ot_externa_admitted'] >= 0) & (data_ot_externa['delta_ot_externa_admitted'] <= 30)), 'event_ot_externa_admitted'] = 1\n",
    "\n",
    "#scenario 2\n",
    "#drop whoever was admitted before ot_externa consultation, i.e. negative value for delta_ot_externa_admitted\n",
    "data_ot_externa = data_ot_externa[~(data_ot_externa['delta_ot_externa_admitted'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#scenario 3\n",
    "#censor died patients\n",
    "data_ot_externa['delta_admitted_died'] = (data_ot_externa['died_date'] - data_ot_externa['admitted_ot_externa_date']).dt.days\n",
    "data_ot_externa.loc[data_ot_externa['delta_admitted_died'] < 0, 'delta_admitted_died'] = np.NaN\n",
    "data_ot_externa.loc[((data_ot_externa['delta_admitted_died'] >= 0) & (data_ot_externa['delta_admitted_died'] <= 30)), 'event_ot_externa_admitted'] = 0\n",
    "\n",
    "#scenario 3\n",
    "#censor deregistered patients\n",
    "data_ot_externa['delta_admitted_deregistered'] = (data_ot_externa['deregistered_date'] - data_ot_externa['admitted_ot_externa_date']).dt.days\n",
    "data_ot_externa.loc[data_ot_externa['delta_admitted_deregistered'] < 0, 'delta_admitted_deregistered'] = np.NaN\n",
    "data_ot_externa.loc[((data_ot_externa['delta_admitted_deregistered'] > 0) & (data_ot_externa['delta_admitted_deregistered'] <= 30)), 'event_ot_externa_admitted'] = 0\n",
    "\n",
    "#agg scenario 3s\n",
    "data_ot_externa['delta_admitted_died_deregistered'] = data_ot_externa['delta_admitted_deregistered'].combine_first(data_ot_externa['delta_admitted_died'])\n",
    "data_ot_externa.loc[data_ot_externa['delta_admitted_died_deregistered'] < 0, 'delta_admitted_died_deregistered'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#scenario 1\n",
    "#any other patients (nothing happened)\n",
    "data_ot_externa['event_ot_externa_admitted'] = data_ot_externa['event_ot_externa_admitted'].replace(np.NaN, 0)\n",
    "\n",
    "#assign values for duration column\n",
    "data_ot_externa['duration_ot_externa_admitted'] = data_ot_externa['delta_ot_externa_admitted'].combine_first(data_ot_externa['delta_admitted_died_deregistered'])\n",
    "data_ot_externa['duration_ot_externa_admitted'] = data_ot_externa['duration_ot_externa_admitted'].replace(np.NaN, 30)\n",
    "data_ot_externa.loc[(data_ot_externa['duration_ot_externa_admitted'] > 30), 'duration_ot_externa_admitted'] = 30\n",
    "\n",
    "#give value 1 to event_ot_externa_admitted if duration_ot_externa_admitted is greater or equal to 0 and less than 30\n",
    "data_ot_externa.loc[((data_ot_externa['duration_ot_externa_admitted'] >= 0) & (data_ot_externa['duration_ot_externa_admitted'] < 30)), 'event_ot_externa_admitted'] = 1\n",
    "\n",
    "#drop any rows with value 0 in duration column\n",
    "data_ot_externa = data_ot_externa[~(data_ot_externa['duration_ot_externa_admitted'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#scenario2 (uncensoring) again to prevent conflict with other scenarios\n",
    "data_ot_externa.loc[((data_ot_externa['delta_ot_externa_admitted'] > 0) & (data_ot_externa['delta_ot_externa_admitted'] < 30)), 'event_ot_externa_admitted'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3- dealing with uninteresting and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#drop anybody with age less than 18 or 0!\n",
    "data_ot_externa = data_ot_externa[~(data_ot_externa['age'] < 18)] \n",
    "data_ot_externa['age'][data_ot_externa['age'] < 0] = np.nan\n",
    "#drop age_cat 0-4 and 5-14\n",
    "data_ot_externa = data_ot_externa[data_ot_externa['age_cat'] != '0-4']\n",
    "data_ot_externa = data_ot_externa[data_ot_externa['age_cat'] != '5-14'] \n",
    "#assign 0 (missingness) to all bmi values less than 10\n",
    "data_ot_externa['bmi'][data_ot_externa['bmi'] < 10] = 0\n",
    "#replace 0s in bmi with nans\n",
    "data_ot_externa['bmi'] = data_ot_externa['bmi'].replace({0:np.nan})\n",
    "#replace negatives in antibacterial_brit with nans\n",
    "data_ot_externa['antibacterial_brit'][data_ot_externa['antibacterial_brit'] < 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#replace strings with numerics\n",
    "dict_sex = {'F': 0, 'M': 1}\n",
    "dict_smoking = {'S': 1, 'E': 2, 'N':3, 'M':np.nan}\n",
    "\n",
    "data_ot_externa = data_ot_externa.replace({\"sex\": dict_sex})\n",
    "data_ot_externa = data_ot_externa.replace({\"smoking\": dict_smoking})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#drop rows with missing region\n",
    "if ('region' in data_ot_externa.columns) and (data_ot_externa['region'].isnull().sum() > 0):\n",
    "   data_ot_externa = data_ot_externa[data_ot_externa['region'].notna()]\n",
    "\n",
    "#replace rows with missing antibiotics with 0\n",
    "if ('antibacterial_brit' in data_ot_externa.columns) and (data_ot_externa['antibacterial_brit'].isnull().sum() > 0):\n",
    "    data_ot_externa['antibacterial_brit'] = data_ot_externa['antibacterial_brit'].fillna(0)\n",
    "\n",
    "#replace rows with missing ethnicity with 0\n",
    "if ('ethnicity' in data_ot_externa.columns) and (data_ot_externa['ethnicity'].isnull().sum() > 0):\n",
    "    data_ot_externa['ethnicity'] = data_ot_externa['ethnicity'].fillna(0)\n",
    "\n",
    "#replace rows with missing smoking with 0\n",
    "if ('smoking' in data_ot_externa.columns) and (data_ot_externa['smoking'].isnull().sum() > 0):\n",
    "    data_ot_externa['smoking'] = data_ot_externa['smoking'].fillna(0)\n",
    "\n",
    "#replace rows with missing imd with 0\n",
    "if ('imd' in data_ot_externa.columns) and (data_ot_externa['imd'].isnull().sum() > 0):\n",
    "    data_ot_externa['imd'] = data_ot_externa['imd'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#missing values of bmi assign 5 and 0; categorise bmi\n",
    "data_ot_externa['bmi_cat'] = 5\n",
    "\n",
    "for idx, x in enumerate(data_ot_externa['bmi_cat']):\n",
    "    if data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi')] >= 30:\n",
    "        data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi_cat')] = 1 #'Obese'\n",
    "    if (data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi')] >= 25) and (data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi')] < 30):\n",
    "        data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi_cat')] = 2 #'Overweight'\n",
    "    if (data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi')] >= 18.5) and (data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi')] < 25):\n",
    "        data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi_cat')] = 3 #'Healthy weight'\n",
    "    if data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi')] < 18.5:\n",
    "        data_ot_externa.iat[idx, data_ot_externa.columns.get_loc('bmi_cat')] = 4 #'Underweight'\n",
    "\n",
    "if ('bmi_cat' in data_ot_externa.columns) and (data_ot_externa['bmi_cat'].isnull().sum() > 0):\n",
    "    data_ot_externa['bmi_cat'] = data_ot_externa['bmi_cat'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##add variable ab_type_cat and assign 0 to its missings\n",
    "#find ab types\n",
    "ab_series = pd.value_counts(data_ot_externa.ab_type)\n",
    "#take percentages of ab categories\n",
    "ab_category_perc = ab_series/ab_series.sum() * 100\n",
    "#take first 2 categories of abs\n",
    "mask = (ab_category_perc).lt(ab_category_perc[1])\n",
    "#replace category other with categories with 4th percentage or more (less frequent abs)\n",
    "data_ot_externa['ab_type_cat'] = np.where(data_ot_externa['ab_type'].isin(ab_series[mask].index),'other',data_ot_externa['ab_type'])\n",
    "#assign no to non ab users\n",
    "data_ot_externa.loc[data_ot_externa['ot_externa_ab_date'].isnull(), 'ab_type_cat'] = 'no'\n",
    "#fill nas with 0 and then assign other to 0s\n",
    "data_ot_externa['ab_type_cat'] = data_ot_externa['ab_type_cat'].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4- translate values of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#define dictionaries\n",
    "dict_sex = {0: 'female', 1: 'male'}\n",
    "dict_ethnicity = {1.0: 'white', 2.0: 'mixed', 3.0: 'asian', 4.0: 'black', 5.0: 'other', 0: 'unknown'}\n",
    "dict_smoking = {1.0:'smoker', 2.0:'ex_smoker', 3.0:'never_smoked', 0: 'unknown'}\n",
    "dict_imd = {1:'very_affluent', 2:'affluent', 3:'medium', 4:'unaffluent', 5:'very_unaffluent', 0:'unknown'}\n",
    "dict_bmi = {1:'obese', 2:'overweight', 3:'healthy_weight', 4:'underweight', 5:'unknown', 0:'unknown'}\n",
    "dict_flu = {0: 'no', 1: 'yes'}\n",
    "dict_region = {'London': 'london', 'North East': 'north_east', 'North West': 'north_west', 'East': 'east', 'West Midlands': 'west_midlands', 'Yorkshire and The Humber': 'yorkshire', 'South East': 'south_east', 'East Midlands': 'east_midlands', 'South West': 'south_west'}\n",
    "dict_age = {'0-4':'0_4', '5-14':'5_14', '15-24':'15_24', '25-34':'25_34', '35-44':'35_44', '45-54':'45_54', '55-64':'55_64', '65-74':'65_74', '75+':'75_more'}\n",
    "dict_ab_type = {0:'other'}\n",
    "\n",
    "#reoplace values of dictionaries with existing ones\n",
    "data_ot_externa = data_ot_externa.replace({\"sex\": dict_sex})\n",
    "data_ot_externa = data_ot_externa.replace({\"ethnicity\": dict_ethnicity})\n",
    "data_ot_externa = data_ot_externa.replace({\"smoking\": dict_smoking})\n",
    "data_ot_externa = data_ot_externa.replace({\"imd\": dict_imd})\n",
    "data_ot_externa = data_ot_externa.replace({\"bmi_cat\": dict_bmi})\n",
    "data_ot_externa = data_ot_externa.replace({\"flu_vaccine\": dict_flu})\n",
    "data_ot_externa = data_ot_externa.replace({\"region\": dict_region})\n",
    "data_ot_externa = data_ot_externa.replace({\"age_cat\": dict_age})\n",
    "data_ot_externa = data_ot_externa.replace({\"ab_type_cat\": dict_ab_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_ot_externa.ethnicity.value_counts('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_ot_externa.smoking.value_counts('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_ot_externa.bmi_cat.value_counts('NA')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5- categorising and assigning max value for continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#categorise CCI\n",
    "data_ot_externa['CCI_cat'] = pd.cut(data_ot_externa['CCI'], right=False, bins=[0,1,3,5,7,35], labels=['very_low', 'low', 'medium', 'high', 'very_high'])\n",
    "\n",
    "#assign max value to outliers (beyond 95 percentile)\n",
    "data_ot_externa['antibacterial_brit'].clip(0, data_ot_externa['antibacterial_brit'].quantile(0.95), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.heatmap(data_ot_externa[['age', 'bmi', 'CCI', 'antibacterial_brit']].corr(), \n",
    "            annot=True, fmt=\".2f\", annot_kws={\"size\":12},\n",
    "            vmin=-1.0, vmax=1.0)\n",
    "\n",
    "ax.set_xticklabels(['Age', 'BMI', 'CCI', 'Antibacterial prescriptions'], rotation=90, fontsize=9)\n",
    "ax.set_yticklabels(['Age', 'BMI', 'CCI', 'Antibacterial prescriptions',], rotation=0, fontsize=9)                        \n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/hospitalisation_prediction_ot_externa/corr_ot_externa.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- separate data of incident/prevalent and with/without antibiotics and stratified sub-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_ot_externa = data_ot_externa[['age_cat', 'sex', 'CCI_cat', 'flu_vaccine', 'bmi_cat', 'region', 'imd', 'ethnicity', 'smoking', 'season', \n",
    "                                   'antibacterial_brit', 'ot_externa_ab_date', 'ab_type_cat', 'incdt_ot_externa_date', 'date', 'period',\n",
    "                                   'event_ot_externa_admitted', 'duration_ot_externa_admitted'\n",
    "                                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#switch variable ot_externa_ab_date into a binary variable\n",
    "data_ot_externa[['ab_binary']] = data_ot_externa[['ot_externa_ab_date']].where(data_ot_externa[['ot_externa_ab_date']].isnull(), 1).fillna(0).astype(int)\n",
    "#incident and prevalent infection \n",
    "data_ot_externa_incdt = data_ot_externa[data_ot_externa['incdt_ot_externa_date'] == 0]\n",
    "data_ot_externa_prevl = data_ot_externa[data_ot_externa['incdt_ot_externa_date'] == 1]\n",
    "\n",
    "#no antibiotics and incident hospital admission\n",
    "data_ot_externa_no_abs_incdt = data_ot_externa_incdt[data_ot_externa_incdt['ab_binary'] == 0]\n",
    "#with antibiotics and incident hospital admission\n",
    "data_ot_externa_abs_incdt = data_ot_externa_incdt[data_ot_externa_incdt['ab_binary'] == 1]\n",
    "\n",
    "#no antibiotics and prevalent hospital admission\n",
    "data_ot_externa_no_abs_prevl = data_ot_externa_prevl[data_ot_externa_prevl['ab_binary'] == 0]\n",
    "#with antibiotics and prevalent hospital admission\n",
    "data_ot_externa_abs_prevl = data_ot_externa_prevl[data_ot_externa_prevl['ab_binary'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##subcohorts for stratification by period\n",
    "#incident and prevalent infection stratified by time period categories\n",
    "data_ot_externa_incdt_prepandemic = data_ot_externa_incdt[data_ot_externa_incdt['period'] == 'prepandemic']\n",
    "data_ot_externa_incdt_during_pandemic = data_ot_externa_incdt[(data_ot_externa_incdt['period'] == 'during_pandemic')]\n",
    "data_ot_externa_incdt_post_2nd_lockdown = data_ot_externa_incdt[data_ot_externa_incdt['period'] == 'post_2nd_lockdown']\n",
    "data_ot_externa_prevl_prepandemic = data_ot_externa_prevl[data_ot_externa_prevl['period'] == 'prepandemic']\n",
    "data_ot_externa_prevl_during_pandemic = data_ot_externa_prevl[(data_ot_externa_prevl['period'] == 'during_pandemic')]\n",
    "data_ot_externa_prevl_post_2nd_lockdown = data_ot_externa_prevl[data_ot_externa_prevl['period'] == 'post_2nd_lockdown']\n",
    "\n",
    "#no antibiotics and incident hospital admission\n",
    "data_ot_externa_no_abs_incdt_prepandemic = data_ot_externa_incdt_prepandemic[data_ot_externa_incdt_prepandemic['ab_binary'] == 0]\n",
    "data_ot_externa_no_abs_incdt_during_pandemic = data_ot_externa_incdt_during_pandemic[data_ot_externa_incdt_during_pandemic['ab_binary'] == 0]\n",
    "data_ot_externa_no_abs_incdt_post_2nd_lockdown = data_ot_externa_incdt_post_2nd_lockdown[data_ot_externa_incdt_post_2nd_lockdown['ab_binary'] == 0]\n",
    "data_ot_externa_no_abs_prevl_prepandemic = data_ot_externa_prevl_prepandemic[data_ot_externa_prevl_prepandemic['ab_binary'] == 0]\n",
    "data_ot_externa_no_abs_prevl_during_pandemic = data_ot_externa_prevl_during_pandemic[data_ot_externa_prevl_during_pandemic['ab_binary'] == 0]\n",
    "data_ot_externa_no_abs_prevl_post_2nd_lockdown = data_ot_externa_prevl_post_2nd_lockdown[data_ot_externa_prevl_post_2nd_lockdown['ab_binary'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#store data for plotting hosp admission counts and percentages\n",
    "%store data_ot_externa\n",
    "# save data\n",
    "data_ot_externa.to_csv('../output/hospitalisation_prediction_ot_externa/data_ot_externa.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- modelling of antibiotics prediction based on risk of hospital admission\n",
    "### 5-0- summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#make summary tables\n",
    "make_summary_table('ot_externa', 'no_abs_incdt', data_ot_externa_no_abs_incdt)\n",
    "make_summary_table('ot_externa', 'abs_incdt', data_ot_externa_abs_incdt)\n",
    "make_summary_table('ot_externa', 'no_abs_prevl', data_ot_externa_no_abs_prevl)\n",
    "make_summary_table('ot_externa', 'abs_prevl', data_ot_externa_abs_prevl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1- incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_incdt, prob_pred_ot_externa_no_abs_incdt_bin = cox_build('ot_externa', 'incdt', data_ot_externa_incdt, data_ot_externa_no_abs_incdt)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "# try:\n",
    "#build rf and lr models with deciles as predictors\n",
    "prob_pred_enc_lr_rf_incdt, data_enc_dev_incdt, data_enc_val_incdt, lr_pred_dev_incdt, lr_pred_val_incdt = lr_rf_build_risk_deciles('ot_externa', 'incdt_deciles', prob_pred_ot_externa_no_abs_incdt)\n",
    "#calibration plots of rf and lr with deciles\n",
    "calibration_rf_lr('ot_externa', 'incdt_deciles', data_enc_dev_incdt, data_enc_val_incdt, lr_pred_dev_incdt, lr_pred_val_incdt)#, rf_pred_dev_incdt, rf_pred_val_incdt)\n",
    "# except:\n",
    "#     print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")\n",
    "\n",
    "# #make summary table of deciles\n",
    "# make_summary_table_deciles('ot_externa', 'incdt', prob_pred_enc_lr_rf_incdt)\n",
    "\n",
    "# try:\n",
    "#build rf and lr models with all risk factors (e.g. age, sex, ethnicity) as predictors\n",
    "prob_pred_enc_lr_rf_incdt, data_enc_dev_incdt, data_enc_val_incdt, lr_pred_dev_incdt, lr_pred_val_incdt = lr_rf_build_risk_riskfactors('ot_externa', 'incdt_riskfactors', prob_pred_ot_externa_no_abs_incdt)\n",
    "#calibration plots of rf and lr with risk factors\n",
    "calibration_rf_lr('ot_externa', 'incdt_riskfactors', data_enc_dev_incdt, data_enc_val_incdt, lr_pred_dev_incdt, lr_pred_val_incdt)#, rf_pred_dev_incdt, rf_pred_val_incdt)\n",
    "# except:\n",
    "#     print(\"error_3: lr or rf model for risk factors did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# alpha = 0.05\n",
    "# #the coefficients of the regression model\n",
    "# coefs = np.r_[[lr.intercept_], lr.coef_.T.tolist()]\n",
    "# #build an auxiliary dataframe with the constant term in it\n",
    "# X_aux = data_enc_dev_incdt_x.copy()\n",
    "# X_aux.insert(0, 'const', 1)\n",
    "# #degrees of freedom\n",
    "# dof = -np.diff(X_aux.shape)[0]\n",
    "# #Student's t-distribution table lookup\n",
    "# t_val = stats.t.isf(alpha/2, dof)\n",
    "# #MSE of the residuals\n",
    "# mse = np.sum((data_enc_dev_incdt_y['ab_binary'].to_numpy() - lr.predict(data_enc_dev_incdt_x)) ** 2) / dof\n",
    "# #inverse of the variance of the parameters\n",
    "# var_params = np.diag(np.linalg.inv(X_aux.T.dot(X_aux)))\n",
    "# #distance between lower and upper bound of CI\n",
    "# gap = t_val * np.sqrt(mse * var_params)\n",
    "# coef_ints = pd.DataFrame({'coef': coefs.ravel(), 'coef_lower': coefs.ravel() - gap, 'coef_upper': coefs.ravel() + gap})\n",
    "# coef_ints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2- prevalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_prevl, prob_pred_ot_externa_no_abs_prevl_bin = cox_build('ot_externa', 'prevl', data_ot_externa_prevl, data_ot_externa_no_abs_prevl)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "# try:\n",
    "#build rf and lr models with deciles as predictors\n",
    "prob_pred_enc_lr_rf_prevl, data_enc_dev_prevl, data_enc_val_prevl, lr_pred_dev_prevl, lr_pred_val_prevl = lr_rf_build_risk_deciles('ot_externa', 'prevl_deciles', prob_pred_ot_externa_no_abs_prevl)\n",
    "#calibration plots of rf and lr with deciles\n",
    "calibration_rf_lr('ot_externa', 'prevl_deciles', data_enc_dev_prevl, data_enc_val_prevl, lr_pred_dev_prevl, lr_pred_val_prevl)#, rf_pred_dev_prevl, rf_pred_val_prevl)\n",
    "# except:\n",
    "#     print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")\n",
    "\n",
    "# #make summary table of deciles\n",
    "# make_summary_table_deciles('ot_externa', 'prevl', prob_pred_enc_lr_rf_prevl)\n",
    "\n",
    "# try:\n",
    "#build rf and lr models with all risk factors (e.g. age, sex, ethnicity) as predictors\n",
    "prob_pred_enc_lr_rf_prevl, data_enc_dev_prevl, data_enc_val_prevl, lr_pred_dev_prevl, lr_pred_val_prevl = lr_rf_build_risk_riskfactors('ot_externa', 'prevl_riskfactors', prob_pred_ot_externa_no_abs_prevl)\n",
    "#calibration plots of rf and lr with risk factors\n",
    "calibration_rf_lr('ot_externa', 'prevl_riskfactors', data_enc_dev_prevl, data_enc_val_prevl, lr_pred_dev_prevl, lr_pred_val_prevl)#, rf_pred_dev_prevl, rf_pred_val_prevl)\n",
    "# except:\n",
    "#     print(\"error_3: lr or rf model for risk factors did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3- stratification by time period\n",
    "#### 5-3-1- incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_incdt_prepandemic, prob_pred_ot_externa_no_abs_incdt_prepandemic_bin = cox_build('ot_externa', 'incdt_prepandemic', data_ot_externa_incdt_prepandemic, data_ot_externa_no_abs_incdt_prepandemic)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "try:\n",
    "    #build rf and lr models\n",
    "    prob_pred_enc_lr_rf_incdt_prepandemic, data_enc_dev_incdt_prepandemic, data_enc_val_incdt_prepandemic, lr_pred_dev_incdt_prepandemic, lr_pred_val_incdt_prepandemic = lr_rf_build_risk_deciles('ot_externa', 'incdt_prepandemic_deciles', prob_pred_ot_externa_no_abs_incdt_prepandemic)\n",
    "    #calibration plots of rf and lr\n",
    "    calibration_rf_lr('ot_externa', 'incdt_prepandemic', data_enc_dev_incdt_prepandemic, data_enc_val_incdt_prepandemic, lr_pred_dev_incdt_prepandemic, lr_pred_val_incdt_prepandemic)#, rf_pred_dev_incdt_prepandemic, rf_pred_val_incdt_prepandemic)\n",
    "except:\n",
    "    print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_incdt_during_pandemic, prob_pred_ot_externa_no_abs_incdt_during_pandemic_bin = cox_build('ot_externa', 'incdt_during_pandemic', data_ot_externa_incdt_during_pandemic, data_ot_externa_no_abs_incdt_during_pandemic)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "try:\n",
    "    #build rf and lr models\n",
    "    prob_pred_enc_lr_rf_incdt_during_pandemic, data_enc_dev_incdt_during_pandemic, data_enc_val_incdt_during_pandemic, lr_pred_dev_incdt_during_pandemic, lr_pred_val_incdt_during_pandemic = lr_rf_build_risk_deciles('ot_externa', 'incdt_during_pandemic_deciles', prob_pred_ot_externa_no_abs_incdt_during_pandemic)\n",
    "    #calibration plots of rf and lr\n",
    "    calibration_rf_lr('ot_externa', 'incdt_during_pandemic', data_enc_dev_incdt_during_pandemic, data_enc_val_incdt_during_pandemic, lr_pred_dev_incdt_during_pandemic, lr_pred_val_incdt_during_pandemic)#, rf_pred_dev_incdt_during_pandemic, rf_pred_val_incdt_during_pandemic)\n",
    "except:\n",
    "    print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_incdt_post_2nd_lockdown, prob_pred_ot_externa_no_abs_incdt_post_2nd_lockdown_bin = cox_build('ot_externa', 'incdt_post_2nd_lockdown', data_ot_externa_incdt_post_2nd_lockdown, data_ot_externa_no_abs_incdt_post_2nd_lockdown)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "try:\n",
    "    #build rf and lr models\n",
    "    prob_pred_enc_lr_rf_incdt_post_2nd_lockdown, data_enc_dev_incdt_post_2nd_lockdown, data_enc_val_incdt_post_2nd_lockdown, lr_pred_dev_incdt_post_2nd_lockdown, lr_pred_val_incdt_post_2nd_lockdown = lr_rf_build_risk_deciles('ot_externa', 'incdt_post_2nd_lockdown_deciles', prob_pred_ot_externa_no_abs_incdt_post_2nd_lockdown)\n",
    "    #calibration plots of rf and lr\n",
    "    calibration_rf_lr('ot_externa', 'incdt_post_2nd_lockdown', data_enc_dev_incdt_post_2nd_lockdown, data_enc_val_incdt_post_2nd_lockdown, lr_pred_dev_incdt_post_2nd_lockdown, lr_pred_val_incdt_post_2nd_lockdown)#, rf_pred_dev_incdt_post_2nd_lockdown, rf_pred_val_incdt_post_2nd_lockdown)\n",
    "except:\n",
    "    print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3-2- prevalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_prevl_prepandemic, prob_pred_ot_externa_no_abs_prevl_prepandemic_bin = cox_build('ot_externa', 'prevl_prepandemic', data_ot_externa_prevl_prepandemic, data_ot_externa_no_abs_prevl_prepandemic)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "try:\n",
    "    #build rf and lr models\n",
    "    prob_pred_enc_lr_rf_prevl_prepandemic, data_enc_dev_prevl_prepandemic, data_enc_val_prevl_prepandemic, lr_pred_dev_prevl_prepandemic, lr_pred_val_prevl_prepandemic = lr_rf_build_risk_deciles('ot_externa', 'prevl_prepandemic_deciles', prob_pred_ot_externa_no_abs_prevl_prepandemic)\n",
    "    #calibration plots of rf and lr\n",
    "    calibration_rf_lr('ot_externa', 'prevl_prepandemic', data_enc_dev_prevl_prepandemic, data_enc_val_prevl_prepandemic, lr_pred_dev_prevl_prepandemic, lr_pred_val_prevl_prepandemic)#, rf_pred_dev_prevl_prepandemic, rf_pred_val_prevl_prepandemic)\n",
    "except:\n",
    "    print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_prevl_during_pandemic, prob_pred_ot_externa_no_abs_prevl_during_pandemic_bin = cox_build('ot_externa', 'prevl_during_pandemic', data_ot_externa_prevl_during_pandemic, data_ot_externa_no_abs_prevl_during_pandemic)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "try:\n",
    "    #build rf and lr models\n",
    "    prob_pred_enc_lr_rf_prevl_during_pandemic, data_enc_dev_prevl_during_pandemic, data_enc_val_prevl_during_pandemic, lr_pred_dev_prevl_during_pandemic, lr_pred_val_prevl_during_pandemic = lr_rf_build_risk_deciles('ot_externa', 'prevl_during_pandemic_deciles', prob_pred_ot_externa_no_abs_prevl_during_pandemic)\n",
    "    #calibration plots of rf and lr\n",
    "    calibration_rf_lr('ot_externa', 'prevl_during_pandemic', data_enc_dev_prevl_during_pandemic, data_enc_val_prevl_during_pandemic, lr_pred_dev_prevl_during_pandemic, lr_pred_val_prevl_during_pandemic)#, rf_pred_dev_prevl_during_pandemic, rf_pred_val_prevl_during_pandemic)\n",
    "except:\n",
    "    print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #build cox model for hosp prediction using non ab users' data\n",
    "    prob_pred_ot_externa_no_abs_prevl_post_2nd_lockdown, prob_pred_ot_externa_no_abs_prevl_post_2nd_lockdown_bin = cox_build('ot_externa', 'prevl_post_2nd_lockdown', data_ot_externa_prevl_post_2nd_lockdown, data_ot_externa_no_abs_prevl_post_2nd_lockdown)\n",
    "except:\n",
    "    print(\"error_1: cox model did not converge or failed to finalise.\")\n",
    "\n",
    "try:\n",
    "    #build rf and lr models\n",
    "    prob_pred_enc_lr_rf_prevl_post_2nd_lockdown, data_enc_dev_prevl_post_2nd_lockdown, data_enc_val_prevl_post_2nd_lockdown, lr_pred_dev_prevl_post_2nd_lockdown, lr_pred_val_prevl_post_2nd_lockdown = lr_rf_build_risk_deciles('ot_externa', 'prevl_post_2nd_lockdown_deciles', prob_pred_ot_externa_no_abs_prevl_post_2nd_lockdown)\n",
    "    #calibration plots of rf and lr\n",
    "    calibration_rf_lr('ot_externa', 'prevl_post_2nd_lockdown', data_enc_dev_prevl_post_2nd_lockdown, data_enc_val_prevl_post_2nd_lockdown, lr_pred_dev_prevl_post_2nd_lockdown, lr_pred_val_prevl_post_2nd_lockdown)#, rf_pred_dev_prevl_post_2nd_lockdown, rf_pred_val_prevl_post_2nd_lockdown)\n",
    "except:\n",
    "    print(\"error_2: lr or rf model for deciles did not converge or failed to finalise or their calibration plot failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "def0e4482c42eb55e9ecb2c71b72715db3b35e2a95239b0a4aae9445fab5d867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
